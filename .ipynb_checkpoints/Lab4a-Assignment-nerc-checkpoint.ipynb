{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab4a-Assignment about NERC\n",
    "\n",
    "This notebook describes Assignment 3, which is part of Lab 3 of the text mining course. \n",
    "\n",
    "\n",
    "**Learning goals**\n",
    "* going from linguistic input format to representing it in a feature space\n",
    "* working with pretrained word embeddings\n",
    "* train a supervised classifier (SVM)\n",
    "* evaluate a supervised classifier (SVM)\n",
    "* perform feature ablation and gain insight into the contribution of various features\n",
    "\n",
    "We assume you have worked through the following notebook:\n",
    "* **Lab3-Supervised NERC system.ipynb**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Credits\n",
    "The notebooks in this block have been originally created by [Marten Postma](https://martenpostma.github.io) and have been notably extended by [Filip Ilievski](http://ilievski.nl)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [Points: 6] Exercise 1: Exercise 1: NER and NERC definitions\n",
    "* **[2 points] a) Explain what NER is**\n",
    "* **[2 points] b) Explain what NERC is**\n",
    "* **[2 points] c) Explain what the IOB format is and how it represents both the NER and NERC task.**\n",
    "\n",
    "a) Named Entity Recognition - Finding named entities in a text  \n",
    "b) Named Entity Recognition Classification - Classifying the named entities in a category like: Location, Person, Date etc.  \n",
    "c) It is a way of labeling the tokens from a text. A token can be labeled as Inside-Outside-Beginning, meaning the token is inside, outside or at the beginning of an interpretation.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [Points: 20] Exercise 2: Training and evaluating an SVM using CoNLL-2003"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**[4 point] a) Load the CoNLL-2003 training data using the *ConllCorpusReader* and create for both *train.txt* and *test.txt*:**\n",
    "\n",
    "    [2 points]  -a list of dictionaries representing the features for each training instances, e..g,\n",
    "    ```\n",
    "    [\n",
    "    {'words': 'EU', 'pos': 'NNP'}, \n",
    "    {'words': 'rejects', 'pos': 'VBZ'},\n",
    "    ...\n",
    "    ]\n",
    "    ```\n",
    "\n",
    "    [2 points] -the NERC labels associated with each training instance, e.g.,\n",
    "    dictionaries, e.g.,\n",
    "    ```\n",
    "    [\n",
    "    'B-ORG', \n",
    "    'O',\n",
    "    ....\n",
    "    ]\n",
    "    ```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-27T11:56:03.161988Z",
     "start_time": "2020-02-27T11:56:01.660949Z"
    },
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from nltk.corpus.reader import ConllCorpusReader\n",
    "### Adapt the path to point to the nerc_datasets folder on your local machine\n",
    "train = ConllCorpusReader('/Users/sebastiaanvergunst/Desktop/Text Mining/text-mining-ba-master/lab_sessions/lab4/data/nerc_datasets/CONLL2003', 'train.txt', ['words', 'pos', 'ignore', 'chunk'])\n",
    "training_features = []\n",
    "training_gold_labels = []\n",
    "\n",
    "for token, pos, ne_label in train.iob_words():\n",
    "    a_dict = {\n",
    "       'words': token, 'pos': pos\n",
    "    }\n",
    "    training_features.append(a_dict)\n",
    "    training_gold_labels.append(ne_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-27T11:56:04.166804Z",
     "start_time": "2020-02-27T11:56:03.689033Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### Adapt the path to point to the NERC_datasets folder on your local machine\n",
    "test_features = []\n",
    "test_gold_labels = []\n",
    "for token, pos, ne_label in train.iob_words():\n",
    "    a_dict = {\n",
    "       'words': token, 'pos': pos\n",
    "    }\n",
    "    test_features.append(a_dict)\n",
    "    test_gold_labels.append(ne_label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**[2 points] b) provide descriptive statistics about the training and test data:**\n",
    "* How many instances are in train and test?\n",
    "* Provide a frequency distribution of the NERC labels, i.e., how many times does each NERC label occur?\n",
    "* Discuss to what extent the training and test data is balanced (equal amount of instances for each NERC label) and to what extent the training and test data differ?\n",
    "\n",
    "Tip: you can use the following `Counter` functionality to generate frequency list of a list:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-27T12:03:21.714765Z",
     "start_time": "2020-02-27T12:03:21.192947Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Items in train set: 203621   Percentage: 0.8143015964423969\n",
      "Items in test set: 46435   Percentage: 0.1856984035576031\n",
      "Ratio Train/Test: 4.385075912565952 \n",
      "\n",
      "B-ORG\n",
      "Training: 6321 \t\t\tPercentage: 0.03104296708099852\n",
      "Test: 1661 \t\t\tPercentage: 0.03577043178636804\n",
      "ratio Training/Test: 3.805538832028898 \n",
      "\n",
      "O\n",
      "Training: 169578 \t\t\tPercentage: 0.832811939829389\n",
      "Test: 38323 \t\t\tPercentage: 0.8253041886508022\n",
      "ratio Training/Test: 4.424966730162044 \n",
      "\n",
      "B-MISC\n",
      "Training: 3438 \t\t\tPercentage: 0.016884309575142052\n",
      "Test: 702 \t\t\tPercentage: 0.015117906751372886\n",
      "ratio Training/Test: 4.897435897435898 \n",
      "\n",
      "B-PER\n",
      "Training: 6600 \t\t\tPercentage: 0.0324131597428556\n",
      "Test: 1617 \t\t\tPercentage: 0.03482287067944438\n",
      "ratio Training/Test: 4.081632653061225 \n",
      "\n",
      "I-PER\n",
      "Training: 4528 \t\t\tPercentage: 0.022237392017522752\n",
      "Test: 1156 \t\t\tPercentage: 0.0248950145364488\n",
      "ratio Training/Test: 3.916955017301038 \n",
      "\n",
      "B-LOC\n",
      "Training: 7140 \t\t\tPercentage: 0.03506514553999833\n",
      "Test: 1668 \t\t\tPercentage: 0.03592118014428771\n",
      "ratio Training/Test: 4.280575539568345 \n",
      "\n",
      "I-ORG\n",
      "Training: 3704 \t\t\tPercentage: 0.018190658134475325\n",
      "Test: 835 \t\t\tPercentage: 0.017982125551846667\n",
      "ratio Training/Test: 4.435928143712575 \n",
      "\n",
      "I-MISC\n",
      "Training: 1155 \t\t\tPercentage: 0.00567230295499973\n",
      "Test: 216 \t\t\tPercentage: 0.004651663615807042\n",
      "ratio Training/Test: 5.347222222222222 \n",
      "\n",
      "I-LOC\n",
      "Training: 1157 \t\t\tPercentage: 0.005682125124618777\n",
      "Test: 257 \t\t\tPercentage: 0.005534618283622268\n",
      "ratio Training/Test: 4.501945525291829 \n",
      "\n",
      "dict_keys(['O', 'B-LOC', 'B-PER', 'I-PER', 'I-LOC', 'B-MISC', 'I-MISC', 'B-ORG', 'I-ORG'])\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAY0AAAD8CAYAAACLrvgBAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYcAAAD8CAYAAACcjGjIAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nkqQOw0GS1GE4SJI6DAdJUofhIEnq+H/kJnbK40Hn2wAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from collections import Counter \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "train_size = len(training_features)\n",
    "test_size = len(test_features)\n",
    "\n",
    "print('Items in train set:', train_size, '  Percentage:', train_size/(train_size + test_size))\n",
    "print('Items in test set:', test_size, '  Percentage:', test_size/(train_size + test_size))\n",
    "print('Ratio Train/Test:', train_size/test_size, '\\n')\n",
    "\n",
    "count_train = Counter(training_gold_labels)\n",
    "count_test  = Counter(test_gold_labels)\n",
    "\n",
    "for i in count_train.keys():\n",
    "    print(i)\n",
    "    print('Training:', count_train[i], '\\t\\t\\tPercentage:', count_train[i]/train_size)\n",
    "    print('Test:', count_test[i], '\\t\\t\\tPercentage:', count_test[i]/test_size)\n",
    "    print('ratio Training/Test:', count_train[i]/count_test[i], '\\n')\n",
    "\n",
    "\n",
    "def print_counter(counter):\n",
    "    labels, values = zip(*counter.items())\n",
    "\n",
    "    indexes = np.arange(len(labels))\n",
    "    width = 1\n",
    "\n",
    "    plt.bar(indexes, values, width)\n",
    "    plt.xticks(indexes , labels)\n",
    "    plt.show()\n",
    "    \n",
    "\n",
    "print_counter(count_train)\n",
    "print_counter(count_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- We have a train-test split of 81,4% against 18,6%.\n",
    "- There is a big class imbalance in the data, where the 'O' category is overpopulated.\n",
    "- The test and train set both have a large overpopulation of the 'O' category and other categories are similair with some slight differences. Normally this would be reduced by using a stratified split."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**[2 points] c. Explain what one hot encoding is. Explain why we can not use string features to train the SVM.**\n",
    "\n",
    "- One hot encoding is a way to represent categorical features in the same vector, where an index of that vector represents to a category of the features. Multiple one-hot encoded features can be combined into one vector which can be used for training. SVM does only work with numerical data and not with categorical data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**[2 points] d. Concatenate the train and test features (the list of dictionaries) into one list. Load it using the *DictVectorizer*. Afterwards, split it back to training and test.**\n",
    "\n",
    "Tip: You’ve concatenated train and test into one list and then you’ve applied the DictVectorizer.\n",
    "The order of the rows is maintained. You can hence use an index (number of training instances) to split the_array back into train and test. Do NOT use: `\n",
    "from sklearn.model_selection import train_test_split` here.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-25T20:40:06.923608Z",
     "start_time": "2020-02-25T20:40:06.920055Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction import DictVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-25T20:40:07.948836Z",
     "start_time": "2020-02-25T20:40:07.274848Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vec = DictVectorizer()\n",
    "the_array = vec.fit_transform(training_features + test_features)\n",
    "\n",
    "training = the_array[:len(training_features)]\n",
    "test = the_array[len(training_features):]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**[4 points] e. Train the SVM using the train features and labels and evaluate on the test data. Provide a classification report (sklearn.metrics.classification_report).**\n",
    "The train (*lin_clf.fit*) might take a while. On my computer, it took 1min 53s, which is acceptable. Training models normally takes much longer. If it takes more than 5 minutes, you can use a subset for training. Describe the results:\n",
    "* Which NERC labels does the classifier perform well on? Why do you think this is the case?\n",
    "* Which NERC labels does the classifier perform poorly on? Why do you think this is the case?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-04T10:57:39.270315Z",
     "start_time": "2020-03-04T10:57:39.260700Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn import svm\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import make_pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-25T20:50:03.844439Z",
     "start_time": "2020-02-25T20:40:11.972516Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sebastiaanvergunst/anaconda3/lib/python3.6/site-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "pipe = make_pipeline(svm.LinearSVC())\n",
    "param_grid = {'linearsvc__C': [100]}\n",
    "grid_svc = GridSearchCV(pipe, param_grid, cv=3).fit(training, training_gold_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-25T20:50:04.179335Z",
     "start_time": "2020-02-25T20:50:03.847091Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       B-LOC       0.80      0.79      0.79      1668\n",
      "      B-MISC       0.76      0.67      0.71       702\n",
      "       B-ORG       0.80      0.52      0.63      1661\n",
      "       B-PER       0.85      0.45      0.59      1617\n",
      "       I-LOC       0.62      0.54      0.57       257\n",
      "      I-MISC       0.56      0.58      0.57       216\n",
      "       I-ORG       0.70      0.47      0.57       835\n",
      "       I-PER       0.33      0.85      0.48      1156\n",
      "           O       0.99      0.99      0.99     38323\n",
      "\n",
      "    accuracy                           0.92     46435\n",
      "   macro avg       0.71      0.65      0.66     46435\n",
      "weighted avg       0.94      0.92      0.92     46435\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(test_gold_labels, grid_svc.predict(test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**[6 points] f. Train a model that uses the embeddings of these words as inputs. Test again on the same data as in 2e. Generate a classification report and compare the results with the classifier you built in 2e.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-04T10:53:24.767664Z",
     "start_time": "2020-03-04T10:52:04.831363Z"
    }
   },
   "outputs": [],
   "source": [
    "import gensim\n",
    "word_embedding_model = gensim.models.KeyedVectors.load_word2vec_format('/Users/sebastiaanvergunst/Desktop/Text Mining/text-mining-ba-master/lab_sessions/lab2/data/model/GoogleNews-vectors-negative300.bin', binary=True)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-04T10:57:00.544222Z",
     "start_time": "2020-03-04T10:57:00.323353Z"
    }
   },
   "outputs": [],
   "source": [
    "import spacy\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "\n",
    "def get_w2v(word, word_embedding_model):\n",
    "    if word in word_embedding_model:\n",
    "        vector=word_embedding_model[word]\n",
    "    else: \n",
    "        vector=[0]*300\n",
    "    return vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-04T10:57:05.596426Z",
     "start_time": "2020-03-04T10:57:01.183683Z"
    }
   },
   "outputs": [],
   "source": [
    "from nltk.corpus.reader import ConllCorpusReader\n",
    "### Adapt the path to point to the nerc_datasets folder on your local machine\n",
    "train = ConllCorpusReader('/Users/sebastiaanvergunst/Desktop/Text Mining/text-mining-ba-master/lab_sessions/lab4/data/nerc_datasets/CONLL2003', 'train.txt', ['words', 'pos', 'ignore', 'chunk'])\n",
    "training_features = []\n",
    "training_gold_labels = []\n",
    "test_features = []\n",
    "test_gold_labels = []\n",
    "\n",
    "for token, pos, ne_label in train.iob_words():\n",
    "    training_features.append(get_w2v(token, word_embedding_model))\n",
    "    training_gold_labels.append(ne_label)\n",
    "\n",
    "for token, pos, ne_label in train.iob_words():\n",
    "    test_features.append(get_w2v(token, word_embedding_model))\n",
    "    test_gold_labels.append(ne_label)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-04T11:48:25.208234Z",
     "start_time": "2020-03-04T10:58:00.831557Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sebastiaanvergunst/anaconda3/envs/text_mining/lib/python3.7/site-packages/sklearn/svm/base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/Users/sebastiaanvergunst/anaconda3/envs/text_mining/lib/python3.7/site-packages/sklearn/svm/base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/Users/sebastiaanvergunst/anaconda3/envs/text_mining/lib/python3.7/site-packages/sklearn/svm/base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/Users/sebastiaanvergunst/anaconda3/envs/text_mining/lib/python3.7/site-packages/sklearn/svm/base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "pipe = make_pipeline(svm.LinearSVC())\n",
    "param_grid = {'linearsvc__C': [100]}\n",
    "grid_svc = GridSearchCV(pipe, param_grid, cv=3).fit(training_features, training_gold_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-04T11:48:28.424227Z",
     "start_time": "2020-03-04T11:48:25.210526Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       B-LOC       0.80      0.80      0.80      7140\n",
      "      B-MISC       0.76      0.67      0.71      3438\n",
      "       B-ORG       0.68      0.56      0.61      6321\n",
      "       B-PER       0.76      0.70      0.73      6600\n",
      "       I-LOC       0.65      0.50      0.57      1157\n",
      "      I-MISC       0.70      0.30      0.42      1155\n",
      "       I-ORG       0.60      0.39      0.47      3704\n",
      "       I-PER       0.59      0.59      0.59      4528\n",
      "           O       0.97      1.00      0.98    169578\n",
      "\n",
      "    accuracy                           0.93    203621\n",
      "   macro avg       0.72      0.61      0.65    203621\n",
      "weighted avg       0.93      0.93      0.93    203621\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(test_gold_labels, grid_svc.predict(test_features)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [Points: 14] Exercise 3: feature inspection using the [Annotated Corpus for Named Entity Recognition](https://www.kaggle.com/abhinavwalia95/entity-annotated-corpus)\n",
    "**[6 points] a. Perform the same steps as in the previous exercise. Make sure you end up for both the training part (*df_train*) and the test part (*df_test*) with:**\n",
    "* the features representation using **DictVectorizer**\n",
    "* the NERC labels in a list\n",
    "\n",
    "Please note that this is the same setup as in the previous exercise:\n",
    "* load both train and test using:\n",
    "    * list of dictionaries for features\n",
    "    * list of NERC labels\n",
    "* combine train and test features in a list and represent them using one hot encoding\n",
    "* train using the training features and NERC labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-25T20:23:06.861055Z",
     "start_time": "2020-02-25T20:23:06.205892Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-25T20:23:11.714132Z",
     "start_time": "2020-02-25T20:23:07.449897Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "b'Skipping line 281837: expected 25 fields, saw 34\\n'\n"
     ]
    }
   ],
   "source": [
    "##### Adapt the path to point to your local copy of NERC_datasets\n",
    "path = '/Users/sebastiaanvergunst/Desktop/Text Mining/text-mining-ba-master/lab_sessions/lab4/data/nerc_datasets/kaggle/ner_v2.csv'\n",
    "kaggle_dataset = pandas.read_csv(path, error_bad_lines=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-25T20:23:15.708852Z",
     "start_time": "2020-02-25T20:23:15.702297Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1050795"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(kaggle_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-25T20:23:16.892185Z",
     "start_time": "2020-02-25T20:23:16.884894Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100000 20000\n"
     ]
    }
   ],
   "source": [
    "df_train = kaggle_dataset[:100000]\n",
    "df_test = kaggle_dataset[100000:120000]\n",
    "print(len(df_train), len(df_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-27T12:28:10.395650Z",
     "start_time": "2020-02-27T12:28:10.359355Z"
    }
   },
   "outputs": [],
   "source": [
    "def train_test(remove, df_train=df_train, df_test=df_test, training_labels = df_train['tag'], test_labels = df_test['tag']):\n",
    "    training_features = []\n",
    "    test_features = []\n",
    "    to_drop = ['id', 'sentence_idx', 'tag'] + remove\n",
    "    \n",
    "    training_labels = df_train['tag']\n",
    "    test_labels = df_test['tag']   \n",
    "    \n",
    "    df_train = df_train.drop(columns=to_drop)\n",
    "    df_test = df_test.drop(columns=to_drop)\n",
    "\n",
    "    for index, row in df_train.iterrows():\n",
    "        item = row.to_dict()\n",
    "        training_features.append(item)\n",
    "\n",
    "    for index, row in df_test.iterrows():\n",
    "        item = row.to_dict()\n",
    "        test_features.append(item)\n",
    "\n",
    "    vec = DictVectorizer()\n",
    "    the_array = vec.fit_transform(training_features + test_features)\n",
    "\n",
    "    training = the_array[:len(training_features)]\n",
    "    test = the_array[len(training_features):]\n",
    "    \n",
    "    return training, test, training_labels, test_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**[4 points] b. Train and evaluate the model and provide the classification report:**\n",
    "* use the SVM to predict NERC labels on the test data\n",
    "* evaluate the performance of the SVM on the test data\n",
    "\n",
    "Analyze the performance per NERC label."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-27T12:30:58.508207Z",
     "start_time": "2020-02-27T12:30:11.680720Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sebastiaanvergunst/anaconda3/lib/python3.6/site-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/Users/sebastiaanvergunst/anaconda3/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1268: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       B-art       0.00      0.00      0.00         4\n",
      "       B-eve       0.00      0.00      0.00         0\n",
      "       B-geo       0.85      0.80      0.82       741\n",
      "       B-gpe       0.77      0.90      0.83       296\n",
      "       B-nat       0.62      0.62      0.62         8\n",
      "       B-org       0.66      0.65      0.66       397\n",
      "       B-per       0.78      0.75      0.77       333\n",
      "       B-tim       0.84      0.83      0.84       393\n",
      "       I-art       0.00      0.00      0.00         0\n",
      "       I-eve       0.00      0.00      0.00         0\n",
      "       I-geo       0.99      0.96      0.97       156\n",
      "       I-gpe       0.50      1.00      0.67         2\n",
      "       I-nat       0.80      1.00      0.89         4\n",
      "       I-org       0.95      0.90      0.93       321\n",
      "       I-per       0.95      0.97      0.96       319\n",
      "       I-tim       0.93      0.83      0.88       108\n",
      "           O       0.99      0.99      0.99     16918\n",
      "\n",
      "    accuracy                           0.97     20000\n",
      "   macro avg       0.63      0.66      0.64     20000\n",
      "weighted avg       0.97      0.97      0.97     20000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train, test, train_labels, test_labels = train_test([])\n",
    "pipe = make_pipeline(svm.LinearSVC())\n",
    "param_grid = {'linearsvc__C': [100]}\n",
    "grid_svc = GridSearchCV(pipe, param_grid, cv=3).fit(train, train_labels)\n",
    "print(classification_report(test_labels, grid_svc.predict(test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**[5 points] c. Explain what each feature in the [Annotated Corpus for Named Entity Recognition](https://www.kaggle.com/abhinavwalia95/entity-annotated-corpus) means**\n",
    "You can look at the values of a feature to get insight into what it represents.\n",
    "\n",
    "possible shapes: ['capitalized', 'lowercase', 'punct', 'number', 'other', 'contains-hyphen', 'uppercase', 'abbreviation', 'ending-dot', 'camelcase', 'mixedcase']\n",
    "\n",
    "- 'lemma': lemmatized word\n",
    "- 'next_lemma': the next word lemmatized\n",
    "- 'next-next-lemma':  the next next word lemmatized\n",
    "- 'next-next-pos': POS-tag of next next word\n",
    "- 'next-next-shape': the shape (category) of the next next word\n",
    "- 'next-next-word': the next next word\n",
    "- 'next-pos': the next POS-tag\n",
    "- 'next-shape': the next shape\n",
    "- 'next-word': the next word\n",
    "- 'pos': the POS-tag\n",
    "- 'prev-iob': the previous IOB-tag\n",
    "- 'prev-lemma': the previous lemmatized word\n",
    "- 'prev-pos': the previous POS-tag\n",
    "- 'prev-prev-iob': the previous previous IOB-tag\n",
    "- 'prev-prev-lemma': the previous previous lemmatized word\n",
    "- 'prev-prev-pos': the previous previous POS-tag\n",
    "- 'prev-prev-shape': the previous previous shape \n",
    "- 'prev-prev-word': the previous previous word\n",
    "- 'prev-shape': the previous shape\n",
    "- 'prev-word': the previous word\n",
    "- 'shape': the shape of the current word\n",
    "- 'word': the current word "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**[4 points] d. Describe:**\n",
    "* two features that you think are very useful for the task and why.\n",
    "* two features that you think are not useful for the task and why.\n",
    "\n",
    "Run 4 experiments. In each experiment, you train and evaluate the classifier by removing one features (one of the four you just described).\n",
    "Provide for each experiment the classification report and discuss whether your expectations were met."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-27T12:32:03.089730Z",
     "start_time": "2020-02-27T12:31:13.335482Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sebastiaanvergunst/anaconda3/lib/python3.6/site-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/Users/sebastiaanvergunst/anaconda3/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1268: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       B-art       0.00      0.00      0.00         4\n",
      "       B-eve       0.00      0.00      0.00         0\n",
      "       B-geo       0.86      0.79      0.82       741\n",
      "       B-gpe       0.76      0.89      0.82       296\n",
      "       B-nat       0.56      0.62      0.59         8\n",
      "       B-org       0.67      0.63      0.65       397\n",
      "       B-per       0.78      0.76      0.77       333\n",
      "       B-tim       0.84      0.84      0.84       393\n",
      "       I-art       0.00      0.00      0.00         0\n",
      "       I-eve       0.00      0.00      0.00         0\n",
      "       I-geo       0.97      0.96      0.96       156\n",
      "       I-gpe       0.50      1.00      0.67         2\n",
      "       I-nat       0.50      1.00      0.67         4\n",
      "       I-org       0.95      0.92      0.93       321\n",
      "       I-per       0.95      0.97      0.96       319\n",
      "       I-tim       0.93      0.85      0.89       108\n",
      "           O       0.99      0.99      0.99     16918\n",
      "\n",
      "    accuracy                           0.96     20000\n",
      "   macro avg       0.60      0.66      0.62     20000\n",
      "weighted avg       0.96      0.96      0.96     20000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Experiment 1: removing important feature 'pos'\n",
    "train, test, train_labels, test_labels = train_test(['pos'])\n",
    "pipe = make_pipeline(svm.LinearSVC())\n",
    "param_grid = {'linearsvc__C': [100]}\n",
    "grid_svc = GridSearchCV(pipe, param_grid, cv=3).fit(train, train_labels)\n",
    "print(classification_report(test_labels, grid_svc.predict(test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-27T12:32:55.427846Z",
     "start_time": "2020-02-27T12:32:03.092728Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sebastiaanvergunst/anaconda3/lib/python3.6/site-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/Users/sebastiaanvergunst/anaconda3/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1268: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       B-art       0.00      0.00      0.00         4\n",
      "       B-eve       0.00      0.00      0.00         0\n",
      "       B-geo       0.81      0.80      0.81       741\n",
      "       B-gpe       0.75      0.88      0.81       296\n",
      "       B-nat       0.44      0.50      0.47         8\n",
      "       B-org       0.65      0.61      0.63       397\n",
      "       B-per       0.73      0.69      0.71       333\n",
      "       B-tim       0.85      0.80      0.82       393\n",
      "       I-art       0.00      0.00      0.00         0\n",
      "       I-eve       0.00      0.00      0.00         0\n",
      "       I-geo       0.82      0.70      0.75       156\n",
      "       I-gpe       0.40      1.00      0.57         2\n",
      "       I-nat       0.22      1.00      0.36         4\n",
      "       I-org       0.76      0.68      0.72       321\n",
      "       I-per       0.81      0.82      0.81       319\n",
      "       I-tim       0.76      0.67      0.71       108\n",
      "           O       0.99      0.99      0.99     16918\n",
      "\n",
      "    accuracy                           0.95     20000\n",
      "   macro avg       0.53      0.60      0.54     20000\n",
      "weighted avg       0.95      0.95      0.95     20000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Experiment 2: removing important feature 'prev-iob'\n",
    "train, test, train_labels, test_labels = train_test(['prev-iob'])\n",
    "pipe = make_pipeline(svm.LinearSVC())\n",
    "param_grid = {'linearsvc__C': [100]}\n",
    "grid_svc = GridSearchCV(pipe, param_grid, cv=3).fit(train, train_labels)\n",
    "print(classification_report(test_labels, grid_svc.predict(test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-27T12:33:47.631974Z",
     "start_time": "2020-02-27T12:32:55.431228Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sebastiaanvergunst/anaconda3/lib/python3.6/site-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/Users/sebastiaanvergunst/anaconda3/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1268: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       B-art       0.00      0.00      0.00         4\n",
      "       B-eve       0.00      0.00      0.00         0\n",
      "       B-geo       0.85      0.75      0.80       741\n",
      "       B-gpe       0.90      0.92      0.91       296\n",
      "       B-nat       0.62      0.62      0.62         8\n",
      "       B-org       0.57      0.66      0.61       397\n",
      "       B-per       0.74      0.70      0.72       333\n",
      "       B-tim       0.86      0.79      0.82       393\n",
      "       I-art       0.00      0.00      0.00         0\n",
      "       I-eve       0.00      0.00      0.00         0\n",
      "       I-geo       0.97      0.96      0.96       156\n",
      "       I-gpe       1.00      1.00      1.00         2\n",
      "       I-nat       0.36      1.00      0.53         4\n",
      "       I-org       0.93      0.90      0.91       321\n",
      "       I-per       0.94      0.96      0.95       319\n",
      "       I-tim       0.86      0.83      0.85       108\n",
      "           O       0.99      0.99      0.99     16918\n",
      "\n",
      "    accuracy                           0.96     20000\n",
      "   macro avg       0.62      0.65      0.63     20000\n",
      "weighted avg       0.96      0.96      0.96     20000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Experiment 3: removing all next\n",
    "train, test, train_labels, test_labels = train_test(['next-lemma', 'next-next-lemma', 'next-next-pos',\n",
    "       'next-next-shape', 'next-next-word', 'next-pos', 'next-shape',\n",
    "       'next-word'])\n",
    "pipe = make_pipeline(svm.LinearSVC())\n",
    "param_grid = {'linearsvc__C': [100]}\n",
    "grid_svc = GridSearchCV(pipe, param_grid, cv=3).fit(train, train_labels)\n",
    "print(classification_report(test_labels, grid_svc.predict(test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-27T12:34:59.845911Z",
     "start_time": "2020-02-27T12:33:47.634614Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sebastiaanvergunst/anaconda3/lib/python3.6/site-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/Users/sebastiaanvergunst/anaconda3/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1268: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       B-art       0.10      0.25      0.14         4\n",
      "       B-eve       0.00      0.00      0.00         0\n",
      "       B-geo       0.74      0.71      0.73       741\n",
      "       B-gpe       0.73      0.89      0.80       296\n",
      "       B-nat       0.57      0.50      0.53         8\n",
      "       B-org       0.60      0.54      0.57       397\n",
      "       B-per       0.71      0.59      0.65       333\n",
      "       B-tim       0.81      0.80      0.81       393\n",
      "       I-art       0.00      0.00      0.00         0\n",
      "       I-eve       0.00      0.00      0.00         0\n",
      "       I-geo       0.63      0.49      0.55       156\n",
      "       I-gpe       0.22      1.00      0.36         2\n",
      "       I-nat       0.36      1.00      0.53         4\n",
      "       I-org       0.48      0.47      0.47       321\n",
      "       I-per       0.55      0.63      0.59       319\n",
      "       I-tim       0.42      0.37      0.39       108\n",
      "           O       0.99      0.99      0.99     16918\n",
      "\n",
      "    accuracy                           0.94     20000\n",
      "   macro avg       0.47      0.54      0.48     20000\n",
      "weighted avg       0.94      0.94      0.94     20000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Experiment 4: removing all previous\n",
    "train, test, train_labels, test_labels = train_test(['prev-iob', 'prev-lemma', 'prev-pos', 'prev-prev-iob',\n",
    "       'prev-prev-lemma', 'prev-prev-pos', 'prev-prev-shape', 'prev-prev-word',\n",
    "       'prev-shape', 'prev-word'])\n",
    "pipe = make_pipeline(svm.LinearSVC())\n",
    "param_grid = {'linearsvc__C': [100]}\n",
    "grid_svc = GridSearchCV(pipe, param_grid, cv=3).fit(train, train_labels)\n",
    "print(classification_report(test_labels, grid_svc.predict(test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-27T12:37:09.161117Z",
     "start_time": "2020-02-27T12:34:59.848253Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sebastiaanvergunst/anaconda3/lib/python3.6/site-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/Users/sebastiaanvergunst/anaconda3/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1268: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       B-art       0.00      0.00      0.00         4\n",
      "       B-eve       0.00      0.00      0.00         0\n",
      "       B-geo       0.46      0.53      0.49       741\n",
      "       B-gpe       0.23      0.36      0.28       296\n",
      "       B-nat       0.50      0.50      0.50         8\n",
      "       B-org       0.30      0.29      0.30       397\n",
      "       B-per       0.55      0.54      0.54       333\n",
      "       B-tim       0.37      0.32      0.34       393\n",
      "       I-art       0.00      0.00      0.00         0\n",
      "       I-eve       0.00      0.00      0.00         0\n",
      "       I-geo       0.78      0.87      0.82       156\n",
      "       I-gpe       0.67      1.00      0.80         2\n",
      "       I-nat       0.40      1.00      0.57         4\n",
      "       I-org       0.80      0.83      0.82       321\n",
      "       I-per       0.84      0.94      0.89       319\n",
      "       I-tim       0.70      0.64      0.67       108\n",
      "           O       0.94      0.92      0.93     16918\n",
      "\n",
      "    accuracy                           0.87     20000\n",
      "   macro avg       0.44      0.51      0.47     20000\n",
      "weighted avg       0.88      0.87      0.87     20000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Experiment 5: removing everything about the word itself\n",
    "train, test, train_labels, test_labels = train_test(['lemma','shape', 'word', 'tag', 'pos'])\n",
    "pipe = make_pipeline(svm.LinearSVC())\n",
    "param_grid = {'linearsvc__C': [100]}\n",
    "grid_svc = GridSearchCV(pipe, param_grid, cv=3).fit(train, train_labels)\n",
    "print(classification_report(test_labels, grid_svc.predict(test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-27T12:37:53.664397Z",
     "start_time": "2020-02-27T12:37:09.163472Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sebastiaanvergunst/anaconda3/lib/python3.6/site-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/Users/sebastiaanvergunst/anaconda3/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1268: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       B-art       0.00      0.00      0.00         4\n",
      "       B-eve       0.00      0.00      0.00         0\n",
      "       B-geo       0.86      0.79      0.82       741\n",
      "       B-gpe       0.76      0.90      0.82       296\n",
      "       B-nat       0.71      0.62      0.67         8\n",
      "       B-org       0.66      0.68      0.67       397\n",
      "       B-per       0.77      0.74      0.75       333\n",
      "       B-tim       0.85      0.82      0.84       393\n",
      "       I-art       0.00      0.00      0.00         0\n",
      "       I-eve       0.00      0.00      0.00         0\n",
      "       I-geo       0.99      0.95      0.97       156\n",
      "       I-gpe       0.50      1.00      0.67         2\n",
      "       I-nat       0.57      1.00      0.73         4\n",
      "       I-org       0.95      0.90      0.93       321\n",
      "       I-per       0.95      0.97      0.96       319\n",
      "       I-tim       0.92      0.84      0.88       108\n",
      "           O       0.99      0.99      0.99     16918\n",
      "\n",
      "    accuracy                           0.97     20000\n",
      "   macro avg       0.62      0.66      0.63     20000\n",
      "weighted avg       0.97      0.97      0.97     20000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Experiment 6: removing unimportant feature 'next-next-shape'\n",
    "train, test, train_labels, test_labels = train_test(['next-next-shape'])\n",
    "pipe = make_pipeline(svm.LinearSVC())\n",
    "param_grid = {'linearsvc__C': [100]}\n",
    "grid_svc = GridSearchCV(pipe, param_grid, cv=3).fit(train, train_labels)\n",
    "print(classification_report(test_labels, grid_svc.predict(test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-27T12:38:41.085520Z",
     "start_time": "2020-02-27T12:37:53.666689Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sebastiaanvergunst/anaconda3/lib/python3.6/site-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/Users/sebastiaanvergunst/anaconda3/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1268: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       B-art       0.00      0.00      0.00         4\n",
      "       B-eve       0.00      0.00      0.00         0\n",
      "       B-geo       0.85      0.77      0.81       741\n",
      "       B-gpe       0.76      0.88      0.81       296\n",
      "       B-nat       0.42      0.62      0.50         8\n",
      "       B-org       0.64      0.67      0.66       397\n",
      "       B-per       0.79      0.75      0.77       333\n",
      "       B-tim       0.85      0.84      0.85       393\n",
      "       I-art       0.00      0.00      0.00         0\n",
      "       I-eve       0.00      0.00      0.00         0\n",
      "       I-geo       0.99      0.96      0.97       156\n",
      "       I-gpe       0.40      1.00      0.57         2\n",
      "       I-nat       1.00      1.00      1.00         4\n",
      "       I-org       0.95      0.91      0.93       321\n",
      "       I-per       0.95      0.97      0.96       319\n",
      "       I-tim       0.93      0.84      0.88       108\n",
      "           O       0.99      0.99      0.99     16918\n",
      "\n",
      "    accuracy                           0.96     20000\n",
      "   macro avg       0.62      0.66      0.63     20000\n",
      "weighted avg       0.97      0.96      0.96     20000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Experiment 7: removing unimportant feature 'next-next-word'\n",
    "train, test, train_labels, test_labels = train_test(['next-next-word'])\n",
    "pipe = make_pipeline(svm.LinearSVC())\n",
    "param_grid = {'linearsvc__C': [100]}\n",
    "grid_svc = GridSearchCV(pipe, param_grid, cv=3).fit(train, train_labels)\n",
    "print(classification_report(test_labels, grid_svc.predict(test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**[4 points] e. Describe four features that you think would improve system performance for the NERC task. You do not have to implement them.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**answer:** - "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## End of this notebook"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
