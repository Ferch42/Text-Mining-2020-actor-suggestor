{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab4b - Assignment 4 about NED\n",
    "This notebook describes the LAB-4 assignment of the Text Mining course. It is about Entity linking.\n",
    "\n",
    "**Assignment goals**:\n",
    "* Learn how to evaluate an entity linking system.\n",
    "* Learn how to run two entity linking systems (AIDA and DBpedia Spotlight).\n",
    "* Learn how to interpret the system output and the evaluation results.\n",
    "* Get insight into differences between the two systems.\n",
    "* Be able to describe differences between the two methods in terms of their results.\n",
    "* Be able to propose future improvements based on the observed results.\n",
    "* Get insight into the difficulty of NED and how this depends on specific entity mentions.\n",
    "* Get insight into the relation between NED and NER.\n",
    "* Get insight into other challenges of this task.\n",
    "\n",
    "In this assignment, you are going to work with two systems for entity linking: AIDA and DBpedia Spotlight. You will run them on an entity linking dataset and evaluate their performance. You will perform both quantitative and qualitative analysis of their output, and run one of these systems on your own text. We will reflect on the results of these tasks.\n",
    "\n",
    " We recommend that you go through the notebooks in the following order:\n",
    "* *Read the assignment (see below)*\n",
    "* *Lab4.1-Entity-linking-introduction.ipynb*\n",
    "* *Lab4.2-Entity-linking-evaluation.ipynb*\n",
    "* *Lab4.3-Entity-linking-tools.ipynb*\n",
    "* *Answer the questions of the assignment (see below) using the provided notebooks and submit*\n",
    "\n",
    "**Note:** We will use the dataset Reuters-128 in this assignment. This dataset was introduced in the notebook 'Lab4.3-Entity-linking-tools', so you probably have it already (in case you do not have it make sure you download it from Canvas first and put it in the same location as this notebook). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Credits\n",
    "The notebooks in this block have been created by [Filip Ilievski](http://ilievski.nl)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-04T13:37:28.681943Z",
     "start_time": "2020-03-04T13:37:28.675204Z"
    }
   },
   "outputs": [],
   "source": [
    "from rdflib import Graph, URIRef\n",
    "from tqdm import tqdm ## to create progress bar to measure progress\n",
    "import sys\n",
    "import requests\n",
    "import urllib\n",
    "import urllib.parse\n",
    "from urllib.request import urlopen, Request\n",
    "from urllib.parse import urlencode\n",
    "import xml.etree.cElementTree as ET\n",
    "from lxml import etree\n",
    "import time\n",
    "import json\n",
    "\n",
    "# import our own utility functions and classes\n",
    "import lab4_utils as utils\n",
    "import lab4_classes as classes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Quantitative analysis (17 points)\n",
    "\n",
    "**Exercise 1a** Write code that runs both systems on the full Reuters-128 dataset. (4 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-04T17:11:15.553075Z",
     "start_time": "2020-03-04T17:11:15.533637Z"
    }
   },
   "outputs": [],
   "source": [
    "def aida_disambiguation(articles, aida_url):\n",
    "    \"\"\"\n",
    "    Perform disambiguation with AIDA.\n",
    "    \"\"\"\n",
    "    with tqdm(total=len(articles), file=sys.stdout) as pbar:  \n",
    "        for i, article in enumerate(articles):\n",
    "            \n",
    "            original_content = article.content\n",
    "            new_content=original_content\n",
    "            for entity in reversed(article.entity_mentions):\n",
    "                entity_span=new_content[entity.begin_index: entity.end_index]\n",
    "                new_content=new_content[:entity.begin_index] + '[[' + entity_span + ']]' + new_content[entity.end_index:]\n",
    "\n",
    "            params={\"text\": new_content, \"tag_mode\": 'manual'}\n",
    "            request = Request(aida_url, urlencode(params).encode())\n",
    "            this_json = urlopen(request).read().decode('unicode-escape')\n",
    "            try:\n",
    "                results=json.loads(this_json)\n",
    "            except:\n",
    "                continue\n",
    "\n",
    "            dis_entities={}\n",
    "            for dis_entity in results['mentions']:\n",
    "\n",
    "                if 'bestEntity' in dis_entity.keys():\n",
    "                    best_entity = dis_entity['bestEntity']['kbIdentifier']\n",
    "                    clean_url = best_entity[5:] #SKIP YAGO:\n",
    "                else:\n",
    "                    clean_url = 'NIL'\n",
    "                dis_entities[str(dis_entity['offset'])] = clean_url \n",
    "            \n",
    "            for entity in article.entity_mentions:\n",
    "                start = entity.begin_index\n",
    "                try:\n",
    "                    dis_url = str(dis_entities[str(start)])  \n",
    "                except:\n",
    "                    dis_url = 'NIL'\n",
    "                entity.aida_link = dis_url\n",
    "\n",
    "            pbar.set_description('processed: %d' % (1 + i))\n",
    "            pbar.update(1)\n",
    "    return articles\n",
    "\n",
    "def spotlight_disambiguate(articles, spotlight_url, confidence=0.5):\n",
    "    \"\"\"\n",
    "    Perform disambiguation with DBpedia Spotlight.\n",
    "    \"\"\"\n",
    "    with tqdm(total = len(articles), file = sys.stdout) as pbar:\n",
    "        for i, article in enumerate(articles):\n",
    "            annotation = etree.Element(\"annotation\", text=article.content)\n",
    "\n",
    "            for mention in article.entity_mentions:\n",
    "                sf = etree.SubElement(annotation, \"surfaceForm\")\n",
    "                sf.set(\"name\", mention.mention)\n",
    "                sf.set(\"offset\", str(mention.begin_index))\n",
    "            my_xml = etree.tostring(annotation, xml_declaration = True, encoding='UTF-8')\n",
    "            \n",
    "            results = requests.post(spotlight_url, urllib.parse.urlencode({'text':my_xml, 'confidence': confidence}), \n",
    "                                  headers={'Accept': 'application/json'})\n",
    "            while results.status_code != 200: \n",
    "                print('Trying again...')\n",
    "                results = requests.post(spotlight_url, urllib.parse.urlencode({'text':my_xml, 'confidence': confidence}), \n",
    "                                  headers = {'Accept': 'application/json'})\n",
    "                time.sleep(5)\n",
    "            \n",
    "            j = results.json()\n",
    "            dis_entities={}\n",
    "            if 'Resources' in j: \n",
    "                resources=j['Resources']\n",
    "            else: \n",
    "                resources=[]\n",
    "            for dis_entity in resources:\n",
    "                dis_entities[str(dis_entity['@offset'])] = utils.normalizeURL(dis_entity['@URI'])\n",
    "            \n",
    "            for entity in article.entity_mentions:\n",
    "                start = entity.begin_index\n",
    "                if str(start) in dis_entities:\n",
    "                    dis_url = dis_entities[str(start)]\n",
    "                else:\n",
    "                    dis_url = 'NIL'\n",
    "                entity.spotlight_link = dis_url\n",
    "\n",
    "            pbar.set_description('processed: %d' % (1 + i))\n",
    "            pbar.update(1)\n",
    "\n",
    "            time.sleep(np.random(0,150))\n",
    "    return articles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-04T13:57:50.207299Z",
     "start_time": "2020-03-04T13:54:22.758849Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processed: 2:   2%|▏         | 2/128 [00:11<16:25,  7.82s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sebastiaanvergunst/anaconda3/envs/text_mining/lib/python3.7/site-packages/ipykernel_launcher.py:16: DeprecationWarning: invalid escape sequence '\\/'\n",
      "  app.launch_new_instance()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processed: 128:  96%|█████████▌| 123/128 [03:24<00:08,  1.67s/it]\n"
     ]
    }
   ],
   "source": [
    "reuters_file = 'Reuters-128.ttl'\n",
    "aida_disambiguation_url = \"https://gate.d5.mpi-inf.mpg.de/aida/service/disambiguate\"\n",
    "spotlight_disambiguation_url = \"http://model.dbpedia-spotlight.org/en/disambiguate\"\n",
    "\n",
    "articles = utils.load_article_from_nif_file(reuters_file)\n",
    "processed_aida = aida_disambiguation(articles, aida_disambiguation_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-04T17:11:31.227415Z",
     "start_time": "2020-03-04T17:11:18.153642Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/128 [00:00<?, ?it/s]Trying again...\n",
      "Trying again...\n",
      "Trying again...\n",
      "  0%|          | 0/128 [00:13<?, ?it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-19-e9ac7a21c48c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mproccessed_spotlight\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mspotlight_disambiguate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marticles\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mspotlight_disambiguation_url\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-18-8a2e35ed20bd>\u001b[0m in \u001b[0;36mspotlight_disambiguate\u001b[0;34m(articles, spotlight_url, confidence)\u001b[0m\n\u001b[1;32m     62\u001b[0m                 results = requests.post(spotlight_url, urllib.parse.urlencode({'text':my_xml, 'confidence': confidence}), \n\u001b[1;32m     63\u001b[0m                                   headers = {'Accept': 'application/json'})\n\u001b[0;32m---> 64\u001b[0;31m                 \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m             \u001b[0mj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjson\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "proccessed_spotlight = spotlight_disambiguate(articles, spotlight_disambiguation_url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 1b** Write code that evaluates the two systems on this dataset by computing their overall precision, recall, and F1-score. (5 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-02T21:08:22.892270Z",
     "start_time": "2020-03-02T21:08:22.886346Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def evaluate_entity_linking(system_decisions, gold_decisions):\n",
    "    \n",
    "    tp, fp, fn = 0, 0, 0\n",
    "    \n",
    "    for gold_entity,system_entity in zip(gold_decisions,system_decisions):\n",
    "        if gold_entity=='NIL' and system_entity=='NIL': continue\n",
    "        if gold_entity==system_entity:\n",
    "            tp+=1\n",
    "        else:\n",
    "            if gold_entity!='NIL':\n",
    "                fn+=1\n",
    "            if system_entity!='NIL':\n",
    "                fp+=1\n",
    "\n",
    "#     print('TP: %d; \\nFP: %d, \\nFN: %d' % (tp, fp, fn))            \n",
    "\n",
    "    precision=tp/(tp+fp)\n",
    "    recall=tp/(tp+fn)\n",
    "    f1=2*precision*recall/(precision+recall)\n",
    "    \n",
    "    return precision, recall, f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-02T21:08:33.501101Z",
     "start_time": "2020-03-02T21:08:33.494360Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AIDA System:\n",
      "Precision: 0.61875  Recall: 0.45692307692307693  F1: 0.5256637168141594\n"
     ]
    }
   ],
   "source": [
    "decisions_aida = []\n",
    "gold = []\n",
    "for article in processed_aida:\n",
    "    decisions_aida += [entity.aida_link for entity in article.entity_mentions]\n",
    "    gold += [entity.gold_link for entity in article.entity_mentions]\n",
    "  \n",
    "decisions_spotlight = []\n",
    "for article in proccessed_spotlight:\n",
    "    decisions_spotlight += [entity.spotlight_link for entity in article.entity_mentions]\n",
    "    \n",
    "precision_a, recall_a, f1_a = evaluate_entity_linking(decisions_aida, gold)\n",
    "print('AIDA System:\\nPrecision:', precision_a, ' Recall:', recall_a, ' F1:', f1_a)\n",
    "precision_s, recall_s, f1_s = evaluate_entity_linking(decisions_aida, gold)\n",
    "print('Spotlight System:\\nPrecision:', precision_s, ' Recall:', recall_s, ' F1:', f1_s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 1c** What is the F1-score per system? Which system performs better? Is that also the better system in terms of precision and recall? (4 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Your answer here..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 1d** For each of the systems, compare the precision against the recall: which is higher? What does that mean (hint: think of NIL entities)? (4 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Your answer here..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Qualitative analysis (15 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 2a** Check the entity disambiguation by AIDA against the gold entities on the document with identifier \"http://aksw.org/N3/Reuters-128/82#char=0,1370\" (write code to print the entity mentions, gold links and AIDA links). (2 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-02T17:44:57.169090Z",
     "start_time": "2020-03-02T17:44:54.624109Z"
    }
   },
   "outputs": [],
   "source": [
    "correct_article = [article for article in articles if article.identifier == 'http://aksw.org/N3/Reuters-128/82#char=0,1370'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-02T18:55:08.131836Z",
     "start_time": "2020-03-02T18:54:59.516392Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processed: 1: 100%|██████████| 1/1 [00:08<00:00,  8.58s/it]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sebastiaanvergunst/anaconda3/envs/text_mining/lib/python3.7/site-packages/ipykernel_launcher.py:22: DeprecationWarning: invalid escape sequence '\\/'\n"
     ]
    }
   ],
   "source": [
    "processed_aida = aida_disambiguation([correct_article], aida_disambiguation_url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-02T20:17:21.089089Z",
     "start_time": "2020-03-02T20:17:21.078637Z"
    }
   },
   "source": [
    "for entity in processed_aida[0].entity_mentions:\n",
    "    print('entity:', entity.mention ,', AIDA: ', entity.aida_link, ', GL:', entity.gold_link)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can see in this document that one of the mentions of \"Tokyo\" is disambiguated wrongly by AIDA as `Tokyo` (it should be `Tokyo_Stock_Exchange`). Knowing how AIDA works, what would be your explanation for this error? (4 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**answer: ** The mention of Tokyo is better related to the city and not to the Stock Exchange, so there is a stronger conncetion. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 2b** Check the entity disambiguation by Spotlight against the gold entities on the document \"http://aksw.org/N3/Reuters-128/36#char=0,1146\" (write code to print the entity mentions, gold links and Spotlight links). (2 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-02T20:25:38.842075Z",
     "start_time": "2020-03-02T20:25:38.838951Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "correct_article = [article for article in articles if article.identifier == 'http://aksw.org/N3/Reuters-128/36#char=0,1146'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-02T20:26:43.971043Z",
     "start_time": "2020-03-02T20:26:42.817010Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processed: 1: 100%|██████████| 1/1 [00:01<00:00,  1.15s/it]\n"
     ]
    }
   ],
   "source": [
    "processed_both = spotlight_disambiguate([correct_article], spotlight_disambiguation_url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can see in this document that the mention of \"Group of Seven\" is disambiguated wrongly by Spotlight as `G8` (it should be `G7`). Knowing how Spotlight works, what would be your explanation for this error? (4 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-02T20:29:09.868398Z",
     "start_time": "2020-03-02T20:29:09.848388Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "entity: U.S. Treasury , AIDA:  United_States_Department_of_the_Treasury , GL: United_States_Department_of_the_Treasury\n",
      "entity: Group of Five , AIDA:  Group_of_Five , GL: Group_of_Five\n",
      "entity: Gerhard Stoltenberg , AIDA:  Gerhard_Stoltenberg , GL: Gerhard_Stoltenberg\n",
      "entity: Bundesbank , AIDA:  German_Federal_Bank , GL: Deutsche_Bundesbank\n",
      "entity: Karl Otto Poehl , AIDA:  NIL , GL: Karl_Otto_Pöhl\n",
      "entity: Edouard Balladur , AIDA:  Édouard_Balladur , GL: Édouard_Balladur\n",
      "entity: Jacques de Larosiere , AIDA:  NIL , GL: Jacques_de_Larosière\n",
      "entity: Kiichi Miyazawa , AIDA:  Kiichi_Miyazawa , GL: Kiichi_Miyazawa\n",
      "entity: Satoshi Sumita , AIDA:  NIL , GL: Satoshi_Sumita\n",
      "entity: Robin Leigh Pemberton , AIDA:  NIL , GL: Robin_Leigh-Pemberton,_Baron_Kingsdown\n",
      "entity: Group of Seven , AIDA:  Group_of_Seven , GL: G7\n",
      "entity: Giovanni Goria , AIDA:  Giovanni_Goria , GL: Giovanni_Goria\n",
      "entity: Treasury , AIDA:  HM_Treasury , GL: United_States_Department_of_the_Treasury\n",
      "entity: James Baker , AIDA:  James_Baker , GL: James_Baker\n",
      "entity: Baker , AIDA:  James_Baker , GL: James_Baker\n",
      "entity: Goria , AIDA:  Giovanni_Goria , GL: Giovanni_Goria\n",
      "entity: Group of Seven , AIDA:  Group_of_Seven , GL: G7\n",
      "entity: Paris , AIDA:  Paris , GL: Paris\n",
      "entity: Italy , AIDA:  Kingdom_of_Italy , GL: Italy\n"
     ]
    }
   ],
   "source": [
    "for entity in processed_both[0].entity_mentions:\n",
    "    print('entity:', entity.mention ,', SPOTLIGHT: ', entity.spotlight_link, ', GL:', entity.gold_link)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 2c** In the document with identifier \"http://aksw.org/N3/Reuters-128/67#char=0,1627\":\n",
    "- both systems correctly decide that \"Michel Dufour\" is a `NIL` entity with no representation in the English Wikipedia. \n",
    "- however, Spotlight later decides that \"Dufour\" refers to `Guillaume-Henri_Dufour`\n",
    "\n",
    "How would you help Spotlight fix this error? (Hint: think of how you would know that \"Dufour\" is a NIL entity in that document) (3 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-02T20:32:49.420706Z",
     "start_time": "2020-03-02T20:32:49.416974Z"
    }
   },
   "source": [
    "**answer: ** If it was known before that 'Michel Dufour' is a NIL entity this should be remembered by the disambiguation checker and linked to other occurences. This reduces ambiguity over the document and saves computing resources."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-03T12:36:16.446315Z",
     "start_time": "2020-03-03T12:36:13.537890Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processed: 1: 100%|██████████| 1/1 [00:02<00:00,  2.30s/it]\n",
      "processed: 1: 100%|██████████| 1/1 [00:00<00:00,  1.71it/s]\n",
      "entity: Dominion Textile Inc , SPOTLIGHT: NIL AIDA: NIL , GL: Dominion_Textile\n",
      "entity: Burlington Industries Inc , SPOTLIGHT: NIL AIDA: NIL , GL: Burlington_Industries\n",
      "entity: Michel Dufour , SPOTLIGHT: NIL AIDA: NIL , GL: NIL\n",
      "entity: Reuters , SPOTLIGHT: Reuters AIDA: Reuters , GL: Reuters\n",
      "entity: Dominion Textile , SPOTLIGHT: Dominion_Textile AIDA: Dominion_Textile , GL: Dominion_Textile\n",
      "entity: Dufour , SPOTLIGHT: Guillaume-Henri_Dufour AIDA: Antoine_Dufour , GL: NIL\n",
      "entity: Dominion Textile , SPOTLIGHT: Dominion_Textile AIDA: Dominion_Textile , GL: Dominion_Textile\n",
      "entity: Thomas Bell , SPOTLIGHT: Thom_Bell AIDA: Thom_Bell , GL: NIL\n",
      "entity: Dominion Textile , SPOTLIGHT: Dominion_Textile AIDA: Dominion_Textile , GL: Dominion_Textile\n",
      "entity: Avondale Mills , SPOTLIGHT: Avondale_Mills AIDA: NIL , GL: NIL\n",
      "entity: Dufour , SPOTLIGHT: Guillaume-Henri_Dufour AIDA: Antoine_Dufour , GL: NIL\n",
      "entity: Burlington Industries , SPOTLIGHT: Burlington_Industries AIDA: Burlington_Industries , GL: Burlington_Industries\n",
      "entity: Dominion Textile , SPOTLIGHT: Dominion_Textile AIDA: Dominion_Textile , GL: Dominion_Textile\n",
      "entity: Asher Edelman , SPOTLIGHT: Asher_Edelman AIDA: Asher_Edelman , GL: Asher_Edelman\n",
      "entity: Dominion Textile , SPOTLIGHT: Dominion_Textile AIDA: Dominion_Textile , GL: Dominion_Textile\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sebastiaanvergunst/anaconda3/envs/text_mining/lib/python3.7/site-packages/ipykernel_launcher.py:16: DeprecationWarning: invalid escape sequence '\\/'\n",
      "  app.launch_new_instance()\n"
     ]
    }
   ],
   "source": [
    "correct_article = [article for article in articles if article.identifier == 'http://aksw.org/N3/Reuters-128/67#char=0,1627'][0]\n",
    "processed_both = spotlight_disambiguate([correct_article], spotlight_disambiguation_url)\n",
    "processed_aida=aida_disambiguation([correct_article], aida_disambiguation_url)\n",
    "\n",
    "for entity in processed_both[0].entity_mentions:\n",
    "    print('entity:', entity.mention ,', SPOTLIGHT:', entity.spotlight_link, 'AIDA:', entity.aida_link, ', GL:', entity.gold_link)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Running your own text (14 points)\n",
    "\n",
    "Let's now run one of the tools (you can choose which one) with our own text. You don't need to provide the mentions for this case, you can let the software also perform the recognition of mentions.\n",
    "\n",
    "**Exercise 3a** Add your own text that you would like to be processed. (1 point)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-02T20:40:59.155070Z",
     "start_time": "2020-03-02T20:40:57.168050Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import spacy\n",
    "from spacy import displacy\n",
    "nlp = spacy.load('en')\n",
    "\n",
    "text=\"\"\"\n",
    "Wade Wilson is a dishonorably discharged special forces operative working as a mercenary when he meets Vanessa, a prostitute. They become romantically involved, and a year later she accepts his marriage proposal. Wilson is diagnosed with terminal cancer, and leaves Vanessa without warning so she will not have to watch him die.\n",
    "\n",
    "A mysterious recruiter approaches Wilson, offering an experimental cure for his cancer. He is taken to Ajax and Angel Dust, who inject him with a serum designed to awaken latent mutant genes. They subject Wilson to days of torture to induce stress and trigger any mutation he may have, without success. When Wilson discovers Ajax's real name is Francis and mocks him for it, Ajax leaves Wilson in a hyperbaric chamber that periodically takes him to the verge of asphyxiation over a weekend. This finally activates a superhuman healing ability that cures the cancer but leaves Wilson severely disfigured with burn-like scars over his entire body. He escapes from the chamber and attacks Ajax but relents when told that his disfigurement can be cured. Ajax subdues Wilson and leaves him for dead in the now-burning laboratory.\n",
    "\n",
    "Wilson survives and seeks out Vanessa. He does not reveal to her he is alive fearing her reaction to his new appearance. After consulting with his best friend Weasel, Wilson decides to hunt down Ajax for the cure. He becomes a masked vigilante, adopting the name \"Deadpool\" (from Weasel picking him in a dead pool), and moves into the home of an elderly blind woman named Al. He questions and murders many of Ajax's men until one, the recruiter, reveals his whereabouts. Deadpool intercepts Ajax and a convoy of armed men on an expressway. He kills everyone but Ajax, and demands the cure from him but the X-Man Colossus and his trainee Negasonic Teenage Warhead interrupt him. Colossus wants Deadpool to mend his ways and join the X-Men. Taking advantage of this distraction, Ajax escapes. He goes to Weasel's bar where he learns of Vanessa.\n",
    "\n",
    "Ajax kidnaps Vanessa and takes her to a decommissioned helicarrier in a scrapyard. Deadpool convinces Colossus and Negasonic to help him. They battle Angel Dust and several soldiers while Deadpool fights his way to Ajax. During the battle, Negasonic accidentally destroys the equipment stabilizing the helicarrier. Deadpool protects Vanessa from the collapsing ship, while Colossus carries Negasonic and Angel Dust to safety. Ajax attacks Deadpool again but is overpowered. He reveals there is no cure after all and, despite Colossus's pleading, Deadpool kills him. He promises to try to be more heroic moving forward. Though Vanessa is angry with Wilson for leaving her, she reconciles with him.\n",
    "\"\"\"\n",
    "doc = nlp(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 3b** Write a function to process this text with Spotlight or another tool of your choice, and run it. Print the list of entities that you receive. (3 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-02T20:42:53.406433Z",
     "start_time": "2020-03-02T20:42:53.396606Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from spacy.tokens import Span\n",
    "def spotlight_disambiguate(doc, spotlight_url, confidence=0.5):\n",
    "    entities=[]\n",
    "\n",
    "    annotation = etree.Element(\"annotation\", text=doc.text)\n",
    "\n",
    "    for entity in doc.ents:\n",
    "        sf = etree.SubElement(annotation, \"surfaceForm\")\n",
    "        sf.set(\"name\", entity.text)\n",
    "        sf.set(\"offset\", str(entity.start_char))\n",
    "    my_xml=etree.tostring(annotation, xml_declaration=True, encoding='UTF-8')\n",
    "\n",
    "    results=requests.post(spotlight_url, urllib.parse.urlencode({'text':my_xml, 'confidence': confidence}), \n",
    "                          headers={'Accept': 'application/json'})\n",
    "    j=results.json()\n",
    "    dis_entities={}\n",
    "    if 'Resources' in j: \n",
    "        resources=j['Resources']\n",
    "    else: \n",
    "        resources=[]\n",
    "    for dis_entity in resources:\n",
    "        dis_entities[str(dis_entity['@offset'])] = utils.normalizeURL(dis_entity['@URI'])\n",
    "\n",
    "    for entity in doc.ents:\n",
    "        start = entity.start_char\n",
    "        if str(start) in dis_entities:\n",
    "            dis_url = dis_entities[str(start)]\n",
    "        else:\n",
    "            dis_url = 'NIL'\n",
    "        print(dis_url)\n",
    "        linked_entity = Span(doc, start=entity.start, end=entity.end, label=entity.label_, kb_id=dis_url)\n",
    "        entities.append(linked_entity)\n",
    "\n",
    "    return entities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-02T20:42:06.772962Z",
     "start_time": "2020-03-02T20:42:05.230966Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deadpool\n",
      "Vanessa_Fisk\n",
      "One_Year_Later\n",
      "Woodrow_Wilson\n",
      "Vanessa_Fisk\n",
      "Woodrow_Wilson\n",
      "Ajax_(mythology)\n",
      "Azrieal\n",
      "Woodrow_Wilson\n",
      "Woodrow_Wilson\n",
      "Ajax_(mythology)\n",
      "NIL\n",
      "Ajax_(mythology)\n",
      "Woodrow_Wilson\n",
      "NIL\n",
      "Woodrow_Wilson\n",
      "Ajax_(mythology)\n",
      "Woodrow_Wilson\n",
      "Woodrow_Wilson\n",
      "Vanessa_Fisk\n",
      "Weasel\n",
      "Woodrow_Wilson\n",
      "Ajax_(mythology)\n",
      "Deadpool\n",
      "Weasel\n",
      "Al_Capone\n",
      "Ajax_(mythology)\n",
      "Ajax_(mythology)\n",
      "Ajax_(mythology)\n",
      "Negasonic_Teenage_Warhead\n",
      "Alternative_versions_of_Colossus\n",
      "Deadpool\n",
      "Ajax_(mythology)\n",
      "Weasel\n",
      "Vanessa_Fisk\n",
      "Vanessa_Fisk\n",
      "NIL\n",
      "Azrieal\n",
      "Deadpool\n",
      "Ajax_(mythology)\n",
      "NIL\n",
      "Deadpool\n",
      "Vanessa_Fisk\n",
      "Alternative_versions_of_Colossus\n",
      "NIL\n",
      "Azrieal\n",
      "Deadpool\n",
      "Alternative_versions_of_Colossus\n",
      "Deadpool\n",
      "Vanessa_Fisk\n",
      "Woodrow_Wilson\n",
      "mention: Wade Wilson; type:PERSON; url:Deadpool\n",
      "mention: Vanessa; type:GPE; url:Vanessa_Fisk\n",
      "mention: a year later; type:DATE; url:One_Year_Later\n",
      "mention: Wilson; type:ORG; url:Woodrow_Wilson\n",
      "mention: Vanessa; type:ORG; url:Vanessa_Fisk\n",
      "mention: Wilson; type:ORG; url:Woodrow_Wilson\n",
      "mention: Ajax; type:PERSON; url:Ajax_(mythology)\n",
      "mention: Angel Dust; type:PERSON; url:Azrieal\n",
      "mention: Wilson; type:PERSON; url:Woodrow_Wilson\n",
      "mention: Wilson; type:PERSON; url:Woodrow_Wilson\n",
      "mention: Ajax; type:PERSON; url:Ajax_(mythology)\n",
      "mention: Francis; type:PERSON; url:NIL\n",
      "mention: Ajax; type:PERSON; url:Ajax_(mythology)\n",
      "mention: Wilson; type:ORG; url:Woodrow_Wilson\n",
      "mention: a weekend; type:DATE; url:NIL\n",
      "mention: Wilson; type:ORG; url:Woodrow_Wilson\n",
      "mention: Ajax; type:PERSON; url:Ajax_(mythology)\n",
      "mention: Wilson; type:ORG; url:Woodrow_Wilson\n",
      "mention: Wilson; type:PERSON; url:Woodrow_Wilson\n",
      "mention: Vanessa; type:PERSON; url:Vanessa_Fisk\n",
      "mention: Weasel; type:PERSON; url:Weasel\n",
      "mention: Wilson; type:ORG; url:Woodrow_Wilson\n",
      "mention: Ajax; type:PERSON; url:Ajax_(mythology)\n",
      "mention: Deadpool; type:WORK_OF_ART; url:Deadpool\n",
      "mention: Weasel; type:ORG; url:Weasel\n",
      "mention: Al; type:PERSON; url:Al_Capone\n",
      "mention: Ajax; type:PERSON; url:Ajax_(mythology)\n",
      "mention: Ajax; type:PERSON; url:Ajax_(mythology)\n",
      "mention: Ajax; type:PERSON; url:Ajax_(mythology)\n",
      "mention: Negasonic Teenage Warhead; type:ORG; url:Negasonic_Teenage_Warhead\n",
      "mention: Colossus; type:PERSON; url:Alternative_versions_of_Colossus\n",
      "mention: Deadpool; type:PERSON; url:Deadpool\n",
      "mention: Ajax; type:PERSON; url:Ajax_(mythology)\n",
      "mention: Weasel; type:ORG; url:Weasel\n",
      "mention: Vanessa; type:GPE; url:Vanessa_Fisk\n",
      "mention: Vanessa; type:PERSON; url:Vanessa_Fisk\n",
      "mention: Colossus and Negasonic; type:WORK_OF_ART; url:NIL\n",
      "mention: Angel Dust; type:PERSON; url:Azrieal\n",
      "mention: Deadpool; type:PERSON; url:Deadpool\n",
      "mention: Ajax; type:PERSON; url:Ajax_(mythology)\n",
      "mention: Negasonic; type:PERSON; url:NIL\n",
      "mention: Deadpool; type:PERSON; url:Deadpool\n",
      "mention: Vanessa; type:PERSON; url:Vanessa_Fisk\n",
      "mention: Colossus; type:PERSON; url:Alternative_versions_of_Colossus\n",
      "mention: Negasonic; type:PERSON; url:NIL\n",
      "mention: Angel Dust; type:PERSON; url:Azrieal\n",
      "mention: Deadpool; type:ORG; url:Deadpool\n",
      "mention: Colossus; type:PERSON; url:Alternative_versions_of_Colossus\n",
      "mention: Deadpool; type:PERSON; url:Deadpool\n",
      "mention: Vanessa; type:PERSON; url:Vanessa_Fisk\n",
      "mention: Wilson; type:PERSON; url:Woodrow_Wilson\n"
     ]
    }
   ],
   "source": [
    "spotlight_disambiguation_url = \"http://model.dbpedia-spotlight.org/en/disambiguate\"\n",
    "processed_spotlight = spotlight_disambiguate(doc, spotlight_disambiguation_url)\n",
    "\n",
    "for entity in processed_spotlight:\n",
    "    print('mention: %s; type:%s; url:%s'% (entity.text, entity.label_, entity.kb_id_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 3c** Try changing the value of the confidence parameter and re-runing the annotation in 3b. What is the role of the confidence parameter? What happens if you increase/decrease its value? (4 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**answer:** The confidence parameter is used to tell the disambiguation function how confident it has to be before it can say something about the entity. For our text there is no real change"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-02T20:46:01.150161Z",
     "start_time": "2020-03-02T20:45:59.233087Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deadpool\n",
      "Vanessa_Fisk\n",
      "One_Year_Later\n",
      "Woodrow_Wilson\n",
      "Vanessa_Fisk\n",
      "Woodrow_Wilson\n",
      "Ajax_(mythology)\n",
      "Azrieal\n",
      "Woodrow_Wilson\n",
      "Woodrow_Wilson\n",
      "Ajax_(mythology)\n",
      "Francis_of_Assisi\n",
      "Ajax_(mythology)\n",
      "Woodrow_Wilson\n",
      "NIL\n",
      "Woodrow_Wilson\n",
      "Ajax_(mythology)\n",
      "Woodrow_Wilson\n",
      "Woodrow_Wilson\n",
      "Vanessa_Fisk\n",
      "Weasel\n",
      "Woodrow_Wilson\n",
      "Ajax_(mythology)\n",
      "Deadpool\n",
      "Weasel\n",
      "Al_Capone\n",
      "Ajax_(mythology)\n",
      "Ajax_(mythology)\n",
      "Ajax_(mythology)\n",
      "Negasonic_Teenage_Warhead\n",
      "Alternative_versions_of_Colossus\n",
      "Deadpool\n",
      "Ajax_(mythology)\n",
      "Weasel\n",
      "Vanessa_Fisk\n",
      "Vanessa_Fisk\n",
      "NIL\n",
      "Azrieal\n",
      "Deadpool\n",
      "Ajax_(mythology)\n",
      "NIL\n",
      "Deadpool\n",
      "Vanessa_Fisk\n",
      "Alternative_versions_of_Colossus\n",
      "NIL\n",
      "Azrieal\n",
      "Deadpool\n",
      "Alternative_versions_of_Colossus\n",
      "Deadpool\n",
      "Vanessa_Fisk\n",
      "Woodrow_Wilson\n",
      "mention: Wade Wilson; type:PERSON; url:Deadpool\n",
      "mention: Vanessa; type:GPE; url:Vanessa_Fisk\n",
      "mention: a year later; type:DATE; url:One_Year_Later\n",
      "mention: Wilson; type:ORG; url:Woodrow_Wilson\n",
      "mention: Vanessa; type:ORG; url:Vanessa_Fisk\n",
      "mention: Wilson; type:ORG; url:Woodrow_Wilson\n",
      "mention: Ajax; type:PERSON; url:Ajax_(mythology)\n",
      "mention: Angel Dust; type:PERSON; url:Azrieal\n",
      "mention: Wilson; type:PERSON; url:Woodrow_Wilson\n",
      "mention: Wilson; type:PERSON; url:Woodrow_Wilson\n",
      "mention: Ajax; type:PERSON; url:Ajax_(mythology)\n",
      "mention: Francis; type:PERSON; url:Francis_of_Assisi\n",
      "mention: Ajax; type:PERSON; url:Ajax_(mythology)\n",
      "mention: Wilson; type:ORG; url:Woodrow_Wilson\n",
      "mention: a weekend; type:DATE; url:NIL\n",
      "mention: Wilson; type:ORG; url:Woodrow_Wilson\n",
      "mention: Ajax; type:PERSON; url:Ajax_(mythology)\n",
      "mention: Wilson; type:ORG; url:Woodrow_Wilson\n",
      "mention: Wilson; type:PERSON; url:Woodrow_Wilson\n",
      "mention: Vanessa; type:PERSON; url:Vanessa_Fisk\n",
      "mention: Weasel; type:PERSON; url:Weasel\n",
      "mention: Wilson; type:ORG; url:Woodrow_Wilson\n",
      "mention: Ajax; type:PERSON; url:Ajax_(mythology)\n",
      "mention: Deadpool; type:WORK_OF_ART; url:Deadpool\n",
      "mention: Weasel; type:ORG; url:Weasel\n",
      "mention: Al; type:PERSON; url:Al_Capone\n",
      "mention: Ajax; type:PERSON; url:Ajax_(mythology)\n",
      "mention: Ajax; type:PERSON; url:Ajax_(mythology)\n",
      "mention: Ajax; type:PERSON; url:Ajax_(mythology)\n",
      "mention: Negasonic Teenage Warhead; type:ORG; url:Negasonic_Teenage_Warhead\n",
      "mention: Colossus; type:PERSON; url:Alternative_versions_of_Colossus\n",
      "mention: Deadpool; type:PERSON; url:Deadpool\n",
      "mention: Ajax; type:PERSON; url:Ajax_(mythology)\n",
      "mention: Weasel; type:ORG; url:Weasel\n",
      "mention: Vanessa; type:GPE; url:Vanessa_Fisk\n",
      "mention: Vanessa; type:PERSON; url:Vanessa_Fisk\n",
      "mention: Colossus and Negasonic; type:WORK_OF_ART; url:NIL\n",
      "mention: Angel Dust; type:PERSON; url:Azrieal\n",
      "mention: Deadpool; type:PERSON; url:Deadpool\n",
      "mention: Ajax; type:PERSON; url:Ajax_(mythology)\n",
      "mention: Negasonic; type:PERSON; url:NIL\n",
      "mention: Deadpool; type:PERSON; url:Deadpool\n",
      "mention: Vanessa; type:PERSON; url:Vanessa_Fisk\n",
      "mention: Colossus; type:PERSON; url:Alternative_versions_of_Colossus\n",
      "mention: Negasonic; type:PERSON; url:NIL\n",
      "mention: Angel Dust; type:PERSON; url:Azrieal\n",
      "mention: Deadpool; type:ORG; url:Deadpool\n",
      "mention: Colossus; type:PERSON; url:Alternative_versions_of_Colossus\n",
      "mention: Deadpool; type:PERSON; url:Deadpool\n",
      "mention: Vanessa; type:PERSON; url:Vanessa_Fisk\n",
      "mention: Wilson; type:PERSON; url:Woodrow_Wilson\n"
     ]
    }
   ],
   "source": [
    "spotlight_disambiguation_url = \"http://model.dbpedia-spotlight.org/en/disambiguate\"\n",
    "processed_spotlight = spotlight_disambiguate(doc, spotlight_disambiguation_url, 0.2)\n",
    "\n",
    "for entity in processed_spotlight:\n",
    "    print('mention: %s; type:%s; url:%s'% (entity.text, entity.label_, entity.kb_id_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 3d** Pick one mistake that your tool made on this text (if there are no mistakes, just try annotating another text). Answer the following questions:\n",
    "* Which mistake did the tool make? \n",
    "* Can you say what would be the correct decision instead? \n",
    "* Which of the phases (recognition, candidate generation, disambiguation) seems to have caused this error? \n",
    "\n",
    "(6 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-03T12:42:41.579981Z",
     "start_time": "2020-03-03T12:42:41.573348Z"
    }
   },
   "source": [
    "**answer: ** Most problems are in the disambugiation of Persons. A lot of times only the first or last name is mentioned and it assigns the 'most famous' person with that name in the database tot he entity. Besides this recognition and candidate generation seems to work pretty good."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
