{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.spatial.distance import euclidean\n",
    "import os\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "import re\n",
    "import pandas as pd\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import spacy\n",
    "from nltk.tokenize import word_tokenize\n",
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "import numpy as np\n",
    "from wordcloud import WordCloud\n",
    "from matplotlib import pyplot as plt\n",
    "import random\n",
    "from sklearn.metrics.pairwise import euclidean_distances\n",
    "from tqdm import tqdm\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "import gc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Unnamed: 0.1</th>\n",
       "      <th>Unnamed: 0.1.1</th>\n",
       "      <th>Unnamed: 0.1.1.1</th>\n",
       "      <th>Unnamed: 0.1.1.1.1</th>\n",
       "      <th>Unnamed: 0.1.1.1.1.1</th>\n",
       "      <th>Unnamed: 0.1.1.1.1.1.1</th>\n",
       "      <th>cast</th>\n",
       "      <th>info_json</th>\n",
       "      <th>movie_id</th>\n",
       "      <th>...</th>\n",
       "      <th>Drama</th>\n",
       "      <th>Horror</th>\n",
       "      <th>Family</th>\n",
       "      <th>War</th>\n",
       "      <th>Animation</th>\n",
       "      <th>Biography</th>\n",
       "      <th>Action</th>\n",
       "      <th>Fantasy</th>\n",
       "      <th>summary_no_names</th>\n",
       "      <th>cast_len</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[{'nm0000209': [' Tim Robbins']}, {'nm0327779'...</td>\n",
       "      <td>{'Title': 'War of the Worlds', 'Year': '2005',...</td>\n",
       "      <td>War of the Worlds</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Divorced longshoreman Ray Ferrier works at a d...</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>[{'nm0914612': [' Emma Watson']}, {'nm0341743'...</td>\n",
       "      <td>{'Title': 'Harry Potter and the Deathly Hallow...</td>\n",
       "      <td>Harry Potter and the Deathly Hallows: Part 1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>The Minister of Magic Rufus addresses the wiza...</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>[{'nm0043173': [' Rick Aviles']}, {'nm0534398'...</td>\n",
       "      <td>{'Title': 'The Stand', 'Year': '1994', 'Rated'...</td>\n",
       "      <td>The Stand</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>On June 13 , at a top - secret government labo...</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>[{'nm0000295': [' Kate Beckinsale']}, {'nm0640...</td>\n",
       "      <td>{'Title': 'Van Helsing', 'Year': '2004', 'Rate...</td>\n",
       "      <td>Van Helsing</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Monster hunter Gabriel Van Helsing and friar C...</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>[{'nm0000349': [' Joan Cusack']}, {'nm0000885'...</td>\n",
       "      <td>{'Title': 'Toy Story 3', 'Year': '2010', 'Rate...</td>\n",
       "      <td>Toy Story 3</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Andy is preparing to leave for college . He ha...</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4656</th>\n",
       "      <td>4659</td>\n",
       "      <td>4659</td>\n",
       "      <td>4659</td>\n",
       "      <td>4664</td>\n",
       "      <td>4947</td>\n",
       "      <td>5955</td>\n",
       "      <td>1833</td>\n",
       "      <td>[{'nm0528695': [' Jack Lynn']}, {'nm0377931': ...</td>\n",
       "      <td>{'Title': 'Yentl', 'Year': '1983', 'Rated': 'P...</td>\n",
       "      <td>Yentl</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Barbra Streisand portrays Mendel , a girl livi...</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4657</th>\n",
       "      <td>4660</td>\n",
       "      <td>4660</td>\n",
       "      <td>4660</td>\n",
       "      <td>4665</td>\n",
       "      <td>4950</td>\n",
       "      <td>5958</td>\n",
       "      <td>1836</td>\n",
       "      <td>[{'nm0662116': [' Cecil Parker']}, {'nm0665327...</td>\n",
       "      <td>{'Title': 'The Court Jester', 'Year': '1955', ...</td>\n",
       "      <td>The Court Jester</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Set in medieval , the plot concerns the strugg...</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4658</th>\n",
       "      <td>4661</td>\n",
       "      <td>4661</td>\n",
       "      <td>4661</td>\n",
       "      <td>4666</td>\n",
       "      <td>4951</td>\n",
       "      <td>5959</td>\n",
       "      <td>1839</td>\n",
       "      <td>[{'nm1869008': [' Anya Engel-Adams']}, {'nm000...</td>\n",
       "      <td>{'Title': 'Chi-Raq', 'Year': '2015', 'Rated': ...</td>\n",
       "      <td>Chi-Raq</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>In 's , as the events are narrated by , a war ...</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4659</th>\n",
       "      <td>4662</td>\n",
       "      <td>4662</td>\n",
       "      <td>4662</td>\n",
       "      <td>4667</td>\n",
       "      <td>4952</td>\n",
       "      <td>5960</td>\n",
       "      <td>1840</td>\n",
       "      <td>[{'nm0082848': [' Bindu']}, {'nm2061852': [' A...</td>\n",
       "      <td>{'Title': 'Om Shanti Om', 'Year': '2007', 'Rat...</td>\n",
       "      <td>Om Shanti Om</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>In , Om Prakash Makhija , a junior artist in  ...</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4660</th>\n",
       "      <td>4663</td>\n",
       "      <td>4663</td>\n",
       "      <td>4663</td>\n",
       "      <td>4668</td>\n",
       "      <td>4954</td>\n",
       "      <td>5962</td>\n",
       "      <td>1843</td>\n",
       "      <td>[{'nm0443020': [' Christian Kay']}, {'nm001244...</td>\n",
       "      <td>{'Title': 'Blue Hawaii', 'Year': '1961', 'Rate...</td>\n",
       "      <td>Blue Hawaii</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Chadwick Gates ( Elvis Presley ) has just gott...</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4661 rows Ã— 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Unnamed: 0  Unnamed: 0.1  Unnamed: 0.1.1  Unnamed: 0.1.1.1  \\\n",
       "0              0             0               0                 0   \n",
       "1              1             1               1                 1   \n",
       "2              2             2               2                 2   \n",
       "3              3             3               3                 3   \n",
       "4              4             4               4                 4   \n",
       "...          ...           ...             ...               ...   \n",
       "4656        4659          4659            4659              4664   \n",
       "4657        4660          4660            4660              4665   \n",
       "4658        4661          4661            4661              4666   \n",
       "4659        4662          4662            4662              4667   \n",
       "4660        4663          4663            4663              4668   \n",
       "\n",
       "      Unnamed: 0.1.1.1.1  Unnamed: 0.1.1.1.1.1  Unnamed: 0.1.1.1.1.1.1  \\\n",
       "0                      0                     0                       0   \n",
       "1                      1                     1                       1   \n",
       "2                      2                     2                       2   \n",
       "3                      3                     3                       3   \n",
       "4                      4                     5                       5   \n",
       "...                  ...                   ...                     ...   \n",
       "4656                4947                  5955                    1833   \n",
       "4657                4950                  5958                    1836   \n",
       "4658                4951                  5959                    1839   \n",
       "4659                4952                  5960                    1840   \n",
       "4660                4954                  5962                    1843   \n",
       "\n",
       "                                                   cast  \\\n",
       "0     [{'nm0000209': [' Tim Robbins']}, {'nm0327779'...   \n",
       "1     [{'nm0914612': [' Emma Watson']}, {'nm0341743'...   \n",
       "2     [{'nm0043173': [' Rick Aviles']}, {'nm0534398'...   \n",
       "3     [{'nm0000295': [' Kate Beckinsale']}, {'nm0640...   \n",
       "4     [{'nm0000349': [' Joan Cusack']}, {'nm0000885'...   \n",
       "...                                                 ...   \n",
       "4656  [{'nm0528695': [' Jack Lynn']}, {'nm0377931': ...   \n",
       "4657  [{'nm0662116': [' Cecil Parker']}, {'nm0665327...   \n",
       "4658  [{'nm1869008': [' Anya Engel-Adams']}, {'nm000...   \n",
       "4659  [{'nm0082848': [' Bindu']}, {'nm2061852': [' A...   \n",
       "4660  [{'nm0443020': [' Christian Kay']}, {'nm001244...   \n",
       "\n",
       "                                              info_json  \\\n",
       "0     {'Title': 'War of the Worlds', 'Year': '2005',...   \n",
       "1     {'Title': 'Harry Potter and the Deathly Hallow...   \n",
       "2     {'Title': 'The Stand', 'Year': '1994', 'Rated'...   \n",
       "3     {'Title': 'Van Helsing', 'Year': '2004', 'Rate...   \n",
       "4     {'Title': 'Toy Story 3', 'Year': '2010', 'Rate...   \n",
       "...                                                 ...   \n",
       "4656  {'Title': 'Yentl', 'Year': '1983', 'Rated': 'P...   \n",
       "4657  {'Title': 'The Court Jester', 'Year': '1955', ...   \n",
       "4658  {'Title': 'Chi-Raq', 'Year': '2015', 'Rated': ...   \n",
       "4659  {'Title': 'Om Shanti Om', 'Year': '2007', 'Rat...   \n",
       "4660  {'Title': 'Blue Hawaii', 'Year': '1961', 'Rate...   \n",
       "\n",
       "                                          movie_id  ... Drama Horror  Family  \\\n",
       "0                                War of the Worlds  ...     0      0       0   \n",
       "1     Harry Potter and the Deathly Hallows: Part 1  ...     0      0       1   \n",
       "2                                        The Stand  ...     1      1       0   \n",
       "3                                      Van Helsing  ...     0      0       0   \n",
       "4                                      Toy Story 3  ...     0      0       1   \n",
       "...                                            ...  ...   ...    ...     ...   \n",
       "4656                                         Yentl  ...     1      0       0   \n",
       "4657                              The Court Jester  ...     0      0       1   \n",
       "4658                                       Chi-Raq  ...     1      0       0   \n",
       "4659                                  Om Shanti Om  ...     1      0       0   \n",
       "4660                                   Blue Hawaii  ...     0      0       0   \n",
       "\n",
       "      War  Animation  Biography  Action  Fantasy  \\\n",
       "0       0          0          0       0        0   \n",
       "1       0          0          0       0        1   \n",
       "2       0          0          0       0        1   \n",
       "3       0          0          0       1        1   \n",
       "4       0          1          0       0        1   \n",
       "...   ...        ...        ...     ...      ...   \n",
       "4656    0          0          0       0        0   \n",
       "4657    0          0          0       0        0   \n",
       "4658    0          0          0       0        0   \n",
       "4659    0          0          0       1        0   \n",
       "4660    0          0          0       0        0   \n",
       "\n",
       "                                       summary_no_names  cast_len  \n",
       "0     Divorced longshoreman Ray Ferrier works at a d...        15  \n",
       "1     The Minister of Magic Rufus addresses the wiza...        15  \n",
       "2     On June 13 , at a top - secret government labo...        32  \n",
       "3     Monster hunter Gabriel Van Helsing and friar C...        15  \n",
       "4     Andy is preparing to leave for college . He ha...        15  \n",
       "...                                                 ...       ...  \n",
       "4656  Barbra Streisand portrays Mendel , a girl livi...        15  \n",
       "4657  Set in medieval , the plot concerns the strugg...        15  \n",
       "4658  In 's , as the events are narrated by , a war ...        15  \n",
       "4659  In , Om Prakash Makhija , a junior artist in  ...        15  \n",
       "4660  Chadwick Gates ( Elvis Presley ) has just gott...        15  \n",
       "\n",
       "[4661 rows x 32 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('genre_filtered_movie_no_entities.csv')\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# removing nan items\n",
    "nan_items = []\n",
    "for i,d in data.iterrows():\n",
    "    if type(d['summary_wiki'])!= str:\n",
    "        nan_items.append(i)\n",
    "data = data.drop(nan_items)\n",
    "\n",
    "# removing 0 cast movies\n",
    "data['cast']= [eval(c) for c in data['cast']]\n",
    "data['cast_len'] = [len(c) for c in data['cast']]\n",
    "data = data.drop(data[data['cast_len']==0].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing names\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "stop_words = stopwords.words(\"english\")\n",
    "\n",
    "#filter out names through nerc\n",
    "def remove_names(text):\n",
    "    document = nlp(text)\n",
    "    ents = [e.text for e in document.ents if e.label_ != 'PERSON']\n",
    "    return \" \".join([item.text for item in document if item.text not in ents])\n",
    "\n",
    "#data['summary_no_names'] = data['summary_wiki'].apply(lambda x: remove_names(x))\n",
    "#data.to_csv('genre_filtered_movie_no_entities.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sampling\n",
    "genres = ['Animation', 'Family', 'Fantasy', 'Mystery',\n",
    "       'Sci-Fi', 'Thriller', 'Biography', 'Musical', 'War', 'Western',\n",
    "       'Adventure', 'Horror', 'Drama', 'Romance', 'Action', 'Crime', 'Comedy',\n",
    "       'History']\n",
    "\n",
    "sample_movie_indexes = []\n",
    "for g in genres:\n",
    "    for i,m in data[data[g]==1].sample(2).iterrows():\n",
    "        sample_movie_indexes.append(i)\n",
    "\n",
    "        \n",
    "data_len = len(data)\n",
    "\n",
    "sample_percentage = 10\n",
    "sample_movie_indexes = random.sample(range(data_len), int(data_len/sample_percentage))\n",
    "\n",
    "train_index = [x for x in range(len(data)) if x not in sample_movie_indexes]\n",
    "\n",
    "test_df = data.iloc[sample_movie_indexes, :].reset_index()\n",
    "train_df = data.iloc[train_index,:].reset_index()\n",
    "#test_df.to_csv('test_df.csv')\n",
    "#train_df.to_csv('train_df.csv')\n",
    "test_df =  pd.read_csv('test_df.csv')\n",
    "train_df = pd.read_csv('train_df.csv')\n",
    "test_df['cast']= [eval(c) for c in test_df['cast']]\n",
    "train_df['cast']= [eval(c) for c in train_df['cast']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i,d in data.iterrows():\n",
    "    if len(data['cast']) ==0:\n",
    "        print('fudeu', i , data['cast'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenizer\n",
    "stemmer = WordNetLemmatizer()\n",
    "def tokenize(content):\n",
    "    letters_only = re.sub(\"[^a-zA-Z]\",\" \", content)\n",
    "    lower_case = letters_only.lower()\n",
    "    tokens = word_tokenize(lower_case)\n",
    "    words = [w for w in tokens if not w in stop_words]\n",
    "    stems = [stemmer.lemmatize(word) for word in words]\n",
    "    return(stems)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_topics(topics, feature_names, sorting, topics_per_chunk=6, n_words=20):\n",
    "    for i in range(0, len(topics), topics_per_chunk):\n",
    "        these_topics = topics[i: i + topics_per_chunk]\n",
    "        len_this_chunk = len(these_topics)\n",
    "        words = []\n",
    "        for i in range(n_words):\n",
    "            try:\n",
    "                words.append(feature_names[sorting[these_topics, i]])\n",
    "            except:\n",
    "                pass\n",
    "\n",
    "    #setting up word dictionary for comparison\n",
    "    word_dict = {}\n",
    "    for i in topics:\n",
    "        word_dict.update({i : [word[i] for word in words]})\n",
    "    \n",
    "    return word_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def topic_report(file, df, topics, feature_names, sorting):\n",
    "    \n",
    "    file.write('TOPICS REPORT \\n')\n",
    "    lda_topics = print_topics(topics=range(topics), feature_names=feature_names, sorting=sorting, topics_per_chunk=topics)\n",
    "\n",
    "    for i in range(topics):\n",
    "        file.write('---------------- \\n')\n",
    "        file.write('TOPIC : '+str(i)+ '\\n')\n",
    "        file.write('MOST IMPORTANT WORDS: '+str(lda_topics[i])+'\\n')\n",
    "        file.write('MOVIES OF THIS TOPIC: \\n')\n",
    "        for i,m in df[df['clusters'] == i].iterrows():\n",
    "            file.write(m['movie_id']+\"\\n\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def topic_word_cloud(lda_model,feature_names, topic):\n",
    "    \n",
    "    word_matrix = lda_model.components_[topic]\n",
    "    word_dict = dict(zip(feature_names, word_matrix))\n",
    "    wc = WordCloud(width=800, height=400, max_words=200).generate_from_frequencies(word_dict)\n",
    "    \n",
    "    return wc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#def get_list_of_actors_clustering(lda_model, document_topics, word_vectorizer, text):\n",
    "def get_list_of_actors_clustering(lda_model, document_topics, feature_vector):\n",
    "    #feature_vector = word_vectorizer.transform([text])\n",
    "    topic_distribution = lda_model.transform(feature_vector)\n",
    "    topic = topic_distribution[0].argmax()\n",
    "    related_documents = []\n",
    "    clusters = np.argmax(document_topics, axis = 1)\n",
    "    for i, e in enumerate(clusters):\n",
    "        if e == topic:\n",
    "            related_documents.append(i)\n",
    "    return (topic, related_documents)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#def baseline(document_topics, word_vectorizer, text, k = 10):\n",
    "def baseline(document_topics,feature_vector, k = 10):\n",
    "    #feature_vector = word_vectorizer.transform([text]).toarray()[0]\n",
    "    distances = []\n",
    "    for document in document_topics.toarray():\n",
    "        distances.append(euclidean(feature_vector, document))\n",
    "    \n",
    "    return np.argsort(np.array(distances))[0:k]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#def get_list_of_k_nearest_documents(lda_model, document_topics, word_vectorizer, text, k = 10):\n",
    "def get_list_of_k_nearest_documents(lda_model, document_topics,feature_vector , k = 10):\n",
    "    #feature_vector = word_vectorizer.transform([text])\n",
    "    topic_distribution = lda_model.transform(feature_vector)[0]\n",
    "    distances = []\n",
    "    for document in document_topics:\n",
    "        distances.append(euclidean(topic_distribution, document))\n",
    "    \n",
    "    return np.argsort(np.array(distances))[0:k]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "cast = list(train_df['cast'])\n",
    "test_cast = list(test_df['cast'])\n",
    "def retrieve_cast(cast, document_indexes):\n",
    "    actors = dict()\n",
    "    \n",
    "    for index in document_indexes:\n",
    "        for d in cast[index]:\n",
    "            for v in d.values():\n",
    "                actor = v[0][1:]\n",
    "                if actor not in actors:\n",
    "                    actors[actor] = 1\n",
    "                else:\n",
    "                    actors[actor]+=1\n",
    "    return sorted(actors.items(), key = lambda x:x[1], reverse = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_movie_suggestion(pred_actors, label_actors):\n",
    "    \n",
    "    r_sizes = [20,50,100]\n",
    "    m_ = []\n",
    "    label_actors_set = set([a[0] for a in label_actors])\n",
    "    for s in r_sizes:\n",
    "        pred_actors_set = set([a[0] for a in pred_actors][0:s])\n",
    "        m_.append(len(pred_actors_set.intersection(label_actors_set))/ len(label_actors))\n",
    "    \n",
    "    return m_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_evaluation_file(file, evaluations):\n",
    "    \n",
    "    evaluations = np.array(evaluations).reshape((int(len(evaluations)/3)), 3)\n",
    "    file.write('Evaluation \\n')\n",
    "    for e,r in enumerate(['m20', 'm50', 'm100']):\n",
    "        m = evaluations[:,e]\n",
    "        file.write('--------------------------- \\n')\n",
    "        file.write(r+' mean : '+ str(m.mean())+ '\\n')\n",
    "        file.write(r+' std : '+ str(m.std())+ '\\n')\n",
    "        file.write(r+' max : '+ str(m.max())+ '\\n')\n",
    "        file.write(r+' min : '+ str(m.min())+ '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_actors(actors):\n",
    "    return [actor[0]+' : '+ str(actor[1])+'\\n' for actor in actors][0:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "actors_dict = dict()\n",
    "actors_list = []\n",
    "count = 0\n",
    "for c in data['cast']:\n",
    "    for l in c:\n",
    "        #print(l)\n",
    "        for v in l.values():\n",
    "            assert(len(v) ==1)\n",
    "            actor = v[0][1:]\n",
    "            if actor not in actors_dict.keys():\n",
    "                actors_dict[actor] = count\n",
    "                actors_list.append(actor)\n",
    "                count+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def movie_cast_to_hotform(movie_cast, actor_dictionary):\n",
    "    \n",
    "    target = [[0]*len(actor_dictionary) for _ in range(len(movie_cast))]\n",
    "    for i,m in enumerate(movie_cast):\n",
    "        for d in movie_cast[i]:\n",
    "            actor = list(d.values())[0][0][1:]\n",
    "            target[i][actor_dictionary[actor]] = 1\n",
    "            \n",
    "    return np.array(target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def train_ml_ranking(vector_representations,target):\n",
    "    \n",
    "    assert(len(vector_representations.shape)==2)\n",
    "    \n",
    "    ranking_model = Sequential()\n",
    "    ranking_model.add(Dense(64, activation = 'relu', input_shape = (vector_representations.shape[1],)))\n",
    "    ranking_model.add(Dense(64, activation = 'relu'))\n",
    "    ranking_model.add(Dense(64, activation = 'relu'))\n",
    "    ranking_model.add(Dense(target.shape[1], activation = 'sigmoid'))\n",
    "    ranking_model.compile(optimizer = 'rmsprop', loss = 'categorical_crossentropy', metrics = ['accuracy'])\n",
    "    print(ranking_model.summary())\n",
    "    callbacks = [EarlyStopping(monitor='val_accuracy', patience=5)]\n",
    "    ranking_model.fit(vector_representations, target, epochs=100,validation_split = 0.1 , callbacks = callbacks)\n",
    "    \n",
    "    \n",
    "    return ranking_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ranking_cast(ranks, cast_list):\n",
    "    \n",
    "    assert(len(ranks.shape)==1)\n",
    "    return [actors_list[x] for x in np.flip(ranks)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vectorizing ...\n",
      "baseline ./results/tfidf/baseline.txt\n",
      "training ranking model\n",
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_5 (Dense)              (None, 64)                320064    \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 37894)             2463110   \n",
      "=================================================================\n",
      "Total params: 2,791,494\n",
      "Trainable params: 2,791,494\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Train on 3775 samples, validate on 420 samples\n",
      "Epoch 1/10\n",
      "3775/3775 [==============================] - 9s 2ms/step - loss: 152.8085 - accuracy: 0.0029 - val_loss: 156.9101 - val_accuracy: 0.0048\n",
      "Epoch 2/10\n",
      "3775/3775 [==============================] - 9s 2ms/step - loss: 148.9697 - accuracy: 0.0045 - val_loss: 159.5222 - val_accuracy: 0.0048\n",
      "Epoch 3/10\n",
      "3775/3775 [==============================] - 10s 3ms/step - loss: 147.0870 - accuracy: 0.0045 - val_loss: 160.3824 - val_accuracy: 0.0048\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "466it [01:18,  5.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lda training .. 2\n",
      "word cloud\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3it [00:00, 23.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "experimenting\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "466it [00:19, 24.35it/s]\n",
      "466it [00:19, 23.96it/s]\n",
      "466it [00:20, 22.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training ranking model\n",
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_9 (Dense)              (None, 64)                192       \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 37894)             2463110   \n",
      "=================================================================\n",
      "Total params: 2,471,622\n",
      "Trainable params: 2,471,622\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Train on 3775 samples, validate on 420 samples\n",
      "Epoch 1/10\n",
      "3775/3775 [==============================] - 9s 2ms/step - loss: 152.8991 - accuracy: 0.0019 - val_loss: 157.1523 - val_accuracy: 0.0095\n",
      "Epoch 2/10\n",
      "3775/3775 [==============================] - 8s 2ms/step - loss: 149.6594 - accuracy: 0.0024 - val_loss: 159.3628 - val_accuracy: 0.0119\n",
      "Epoch 3/10\n",
      "3775/3775 [==============================] - 9s 2ms/step - loss: 147.3781 - accuracy: 0.0040 - val_loss: 162.2937 - val_accuracy: 0.0071\n",
      "Epoch 4/10\n",
      "3775/3775 [==============================] - 9s 2ms/step - loss: 145.2586 - accuracy: 0.0037 - val_loss: 164.5269 - val_accuracy: 0.0119\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "271it [00:15, 10.58it/s]"
     ]
    }
   ],
   "source": [
    "# Selecting the vectorizer\n",
    "bow = CountVectorizer(lowercase = True,tokenizer=tokenize, max_features = 5000)\n",
    "tfidf = TfidfVectorizer(analyzer = 'word',tokenizer = tokenize, lowercase = True, max_features = 5000)\n",
    "\n",
    "vectorizers = [tfidf, bow]\n",
    "                \n",
    "# Selecting number of topics\n",
    "number_of_topics = list(range(2,20))\n",
    "                        \n",
    "# Selecting the k nearest\n",
    "k_nearest = [3,5,10]\n",
    "\n",
    "train_ranking_target = movie_cast_to_hotform(cast, actors_dict)\n",
    "\n",
    "for v in vectorizers:\n",
    "    path_string ='./results/'\n",
    "    #print()\n",
    "    if type(v)==TfidfVectorizer:\n",
    "        path_string+='tfidf/'\n",
    "    else:\n",
    "        path_string+='bow/'\n",
    "        \n",
    "    print('Vectorizing ...')\n",
    "    feature_matrix = v.fit_transform(train_df['summary_no_names'])\n",
    "    test_feature_matrix = v.transform(test_df['summary_no_names']).toarray()\n",
    "    # baseline\n",
    "    baseline_path = path_string+'baseline.txt'\n",
    "    print('baseline',baseline_path )\n",
    "    baseline_file = open(baseline_path, 'w+', encoding = 'utf-8')\n",
    "    baseline_file.write('BASELINE FILE \\n')\n",
    "    baseline_evaluation_measure = []\n",
    "    baseline_ranking_evaluation_measure = []\n",
    "    print('training ranking model')\n",
    "    baseline_ranking_model = train_ml_ranking(feature_matrix, train_ranking_target)\n",
    "    baseline_ranking_pred = np.argsort(baseline_ranking_model.predict(test_feature_matrix), axis = 1)\n",
    "    for i,movie in tqdm(test_df.iterrows()):\n",
    "        baseline_file.write('***************\\n')\n",
    "        baseline_file.write('MOVIE :'+movie['movie_id']+'\\n')\n",
    "        baseline_pred_actors = retrieve_cast(cast,baseline(feature_matrix, test_feature_matrix[i]))\n",
    "        baseline_label_actors = retrieve_cast(test_cast, [i])\n",
    "        baseline_ranking_actors = ranking_cast(baseline_ranking_pred[i], actors_list)\n",
    "        baseline_ranking_evaluation_measure += evaluate_movie_suggestion(baseline_ranking_actors, baseline_label_actors)\n",
    "        baseline_evaluation_measure += evaluate_movie_suggestion(baseline_pred_actors, baseline_label_actors)\n",
    "        b = log_actors(baseline_pred_actors)\n",
    "        baseline_file.write('REGULAR Evaluation: \\n')\n",
    "        baseline_file.write('m20 : '+ str(baseline_evaluation_measure[-3])+ \"\\n\")\n",
    "        baseline_file.write('m50 : '+ str(baseline_evaluation_measure[-2])+ \"\\n\")\n",
    "        baseline_file.write('m100 : '+ str(baseline_evaluation_measure[-1])+ \"\\n\")\n",
    "        \n",
    "        baseline_file.write('RANKING Evaluation: \\n')\n",
    "        baseline_file.write('m20 : '+ str(baseline_ranking_evaluation_measure[-3])+ \"\\n\")\n",
    "        baseline_file.write('m50 : '+ str(baseline_ranking_evaluation_measure[-2])+ \"\\n\")\n",
    "        baseline_file.write('m100 : '+ str(baseline_ranking_evaluation_measure[-1])+ \"\\n\")\n",
    "        baseline_file.writelines(b)\n",
    "        \n",
    "    baseline_file.close()\n",
    "    baseline_evaluation_file = open(path_string+'baseline_evaluation.txt', 'w+')\n",
    "    baseline_evaluation_file.write('REGULAR ')\n",
    "    write_evaluation_file(baseline_evaluation_file, baseline_evaluation_measure)\n",
    "    baseline_evaluation_file.write('RANKING ')\n",
    "    write_evaluation_file(baseline_evaluation_file, baseline_ranking_evaluation_measure)\n",
    "    baseline_evaluation_file.close()\n",
    "    \n",
    "    for t in number_of_topics:\n",
    "        gc.collect()\n",
    "        experiment_path=path_string+\"topic\"+str(t)+\"/\"\n",
    "        if not os.path.exists(experiment_path):\n",
    "            os.mkdir(experiment_path)\n",
    "            \n",
    "        lda = LatentDirichletAllocation(n_components = t)\n",
    "        print('lda training ..', t)\n",
    "        document_topics = lda.fit_transform(feature_matrix)\n",
    "        feature_names = np.array(v.get_feature_names())\n",
    "        \n",
    "        clusters =  np.argmax(document_topics, axis=1)\n",
    "        train_df['clusters'] = clusters\n",
    "        cluster_counts = [0 for _ in range(t)]\n",
    "        for c in clusters:\n",
    "            cluster_counts[c]+=1\n",
    "        \n",
    "        plt.figure()\n",
    "        plt.bar(range(t), cluster_counts)\n",
    "        plt.savefig(experiment_path+'cluster_distribution.png')\n",
    "        \n",
    "        t_report_file = open(experiment_path+'topic_report.txt','w+', encoding = 'utf-8')\n",
    "        topic_report(t_report_file, train_df, t, np.array(v.get_feature_names()), np.argsort(lda.components_, axis=1)[:, ::-1])\n",
    "        t_report_file.close()\n",
    "        \n",
    "        word_cloud_path = experiment_path+'wordclouds/'\n",
    "        print('word cloud')\n",
    "        if not os.path.exists(word_cloud_path):\n",
    "            os.mkdir(word_cloud_path)\n",
    "            \n",
    "        for w in range(t):\n",
    "            word_cloud = topic_word_cloud(lda, feature_names, w)\n",
    "            word_cloud.to_file(word_cloud_path+str(w)+'.png')\n",
    "        \n",
    "        print('experimenting')\n",
    "        for k in k_nearest:\n",
    "            experiment_file_name =experiment_path+'k_'+str(k)+'.txt'\n",
    "            experiment_file = open(experiment_file_name, 'w+', encoding = 'utf-8')\n",
    "            experiment_file.write('Experiment \\n')\n",
    "            experiment_file.write(\"## METADATA ## \\n\")\n",
    "            experiment_file.write(\"Vectorizer :\"+ str(v)+'\\n')\n",
    "            experiment_file.write(\"N_topics :\"+ str(t)+'\\n')\n",
    "            experiment_file.write(\"K_nearest :\"+ str(k)+'\\n')\n",
    "            experiment_file.write(\"##############\")\n",
    "            \n",
    "            experiment_evaluation_measure = []\n",
    "            for i,movie in tqdm(test_df.iterrows()):\n",
    "                experiment_file.write('***********************\\n')\n",
    "                experiment_file.write('MOVIE :'+ movie['movie_id']+'\\n')\n",
    "                experiment_pred_actors = retrieve_cast(cast,get_list_of_k_nearest_documents(lda,document_topics, np.array([test_feature_matrix[i]]), k = k))\n",
    "                experiment_label_actors = retrieve_cast(test_cast, [i])\n",
    "                experiment_evaluation_measure += evaluate_movie_suggestion(experiment_pred_actors, experiment_label_actors)\n",
    "                experiment_file.write('Evaluation: \\n')\n",
    "                experiment_file.write('m20 : '+ str(baseline_evaluation_measure[-3])+ \"\\n\")\n",
    "                experiment_file.write('m50 : '+ str(baseline_evaluation_measure[-2])+ \"\\n\")\n",
    "                experiment_file.write('m100 : '+ str(baseline_evaluation_measure[-1])+ \"\\n\")\n",
    "                b = log_actors(experiment_pred_actors)\n",
    "                experiment_file.writelines(b)\n",
    "            \n",
    "            experiment_file.close()\n",
    "            experiment_evaluation_file = open(experiment_path + 'k_'+ str(k)+ '_evaluation.txt', 'w+')\n",
    "            write_evaluation_file(experiment_evaluation_file, experiment_evaluation_measure)\n",
    "            experiment_evaluation_file.close()\n",
    "        \n",
    "        experiment_file_name = experiment_path+'cluster.txt'\n",
    "        experiment_file = open(experiment_file_name, 'w+', encoding = 'utf-8')\n",
    "        experiment_file.write('Experiment cluster \\n')\n",
    "        experiment_evaluation_measure = []\n",
    "        \n",
    "        experiment_ranking_evaluation_measure = []\n",
    "        print('training ranking model')\n",
    "        experiment_ranking_model = train_ml_ranking(document_topics, train_ranking_target)\n",
    "        test_topics = lda.transform(test_feature_matrix)\n",
    "        experiment_ranking_pred = np.argsort(experiment_ranking_model.predict(test_topics), axis = 1)\n",
    "        for i,movie in tqdm(test_df.iterrows()):\n",
    "            experiment_file.write('***********************\\n')\n",
    "            experiment_file.write('MOVIE :'+ movie['movie_id']+'\\n')\n",
    "            \n",
    "            cl, doc_index = get_list_of_actors_clustering(lda, document_topics, np.array([test_feature_matrix[i]]))\n",
    "            experiment_file.write('CLUSTER :' +str(cl)+'\\n')\n",
    "            experiment_pred_actors = retrieve_cast(cast,doc_index)\n",
    "            experiment_label_actors = retrieve_cast(test_cast, [i])\n",
    "            \n",
    "            experiment_ranking_actors = ranking_cast(baseline_ranking_pred[i], actors_list)\n",
    "            experiment_evaluation_measure += evaluate_movie_suggestion(experiment_pred_actors, experiment_label_actors)\n",
    "            experiment_ranking_evaluation_measure += evaluate_movie_suggestion(experiment_ranking_actors, experiment_label_actors)\n",
    "            \n",
    "            b = log_actors(experiment_pred_actors)\n",
    "            experiment_file.write('Evaluation CLUSTERING: \\n')\n",
    "            experiment_file.write('m20 : '+ str(baseline_evaluation_measure[-3])+ \"\\n\")\n",
    "            experiment_file.write('m50 : '+ str(baseline_evaluation_measure[-2])+ \"\\n\")\n",
    "            experiment_file.write('m100 : '+ str(baseline_evaluation_measure[-1])+ \"\\n\")\n",
    "            \n",
    "            experiment_file.write('Evaluation RANKING: \\n')\n",
    "            experiment_file.write('m20 : '+ str(experiment_ranking_evaluation_measure[-3])+ \"\\n\")\n",
    "            experiment_file.write('m50 : '+ str(experiment_ranking_evaluation_measure[-2])+ \"\\n\")\n",
    "            experiment_file.write('m100 : '+ str(experiment_ranking_evaluation_measure[-1])+ \"\\n\")\n",
    "            \n",
    "            experiment_file.writelines(b)\n",
    "        \n",
    "        experiment_file.close()\n",
    "        experiment_evaluation_file = open(experiment_path + 'cluster_evaluation.txt', 'w+')\n",
    "        write_evaluation_file(experiment_evaluation_file, experiment_evaluation_measure)\n",
    "        experiment_evaluation_file.close()\n",
    "        \n",
    "        experiment_ranking_evaluation_file = open(experiment_path + 'ranking_evaluation.txt', 'w+')\n",
    "        write_evaluation_file(experiment_ranking_evaluation_file, experiment_evaluation_measure)\n",
    "        experiment_ranking_evaluation_file.close()\n",
    "        \n",
    "            "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
